{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, FusedBatchNorm, util } from '@tensorflow/tfjs-core';\nimport { BatchNormProgram } from '../batchnorm_gpu';\nimport { BatchNormPackedProgram } from '../batchnorm_packed_gpu';\nexport const batchNorm = ({\n  inputs,\n  backend,\n  attrs\n}) => {\n  const {\n    x,\n    mean,\n    variance,\n    offset,\n    scale\n  } = inputs;\n  util.assert(mean.shape.length === variance.shape.length, () => 'Batch normalization gradient requires mean and variance to have ' + 'equal ranks.');\n  util.assert(offset == null || mean.shape.length === offset.shape.length, () => 'Batch normalization gradient requires mean and offset to have ' + 'equal ranks.');\n  util.assert(scale == null || mean.shape.length === scale.shape.length, () => 'Batch normalization gradient requires mean and scale to have ' + 'equal ranks.');\n  let {\n    varianceEpsilon\n  } = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n  const finalInputs = [x, mean, variance];\n  let offsetShape = null;\n  if (offset != null) {\n    offsetShape = offset.shape;\n    finalInputs.push(offset);\n  }\n  let scaleShape = null;\n  if (scale != null) {\n    scaleShape = scale.shape;\n    finalInputs.push(scale);\n  }\n  const program = env().getBool('WEBGL_PACK_NORMALIZATION') ? new BatchNormPackedProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon) : new BatchNormProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);\n  const output = backend.runWebGLProgram(program, finalInputs, finalInputs[0].dtype);\n  return output;\n};\nexport const batchNormConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'webgl',\n  kernelFunc: batchNorm\n};","map":{"version":3,"names":["env","FusedBatchNorm","util","BatchNormProgram","BatchNormPackedProgram","batchNorm","inputs","backend","attrs","x","mean","variance","offset","scale","assert","shape","length","varianceEpsilon","finalInputs","offsetShape","push","scaleShape","program","getBool","output","runWebGLProgram","dtype","batchNormConfig","kernelName","backendName","kernelFunc"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-backend-webgl/src/kernels/BatchNorm.ts"],"sourcesContent":["\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {BatchNormProgram} from '../batchnorm_gpu';\nimport {BatchNormPackedProgram} from '../batchnorm_packed_gpu';\n\nexport const batchNorm: (params: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendWebGL,\n  attrs: FusedBatchNormAttrs\n}) => TensorInfo = ({inputs, backend, attrs}) => {\n  const {x, mean, variance, offset, scale} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const finalInputs = [x, mean, variance];\n\n  let offsetShape = null;\n  if (offset != null) {\n    offsetShape = offset.shape;\n    finalInputs.push(offset);\n  }\n\n  let scaleShape = null;\n  if (scale != null) {\n    scaleShape = scale.shape;\n    finalInputs.push(scale);\n  }\n\n  const program = env().getBool('WEBGL_PACK_NORMALIZATION') ?\n      new BatchNormPackedProgram(\n          x.shape, mean.shape, variance.shape, offsetShape, scaleShape,\n          varianceEpsilon) :\n      new BatchNormProgram(\n          x.shape, mean.shape, variance.shape, offsetShape, scaleShape,\n          varianceEpsilon);\n  const output =\n      backend.runWebGLProgram(program, finalInputs, finalInputs[0].dtype);\n\n  return output;\n};\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'webgl',\n  kernelFunc: batchNorm as unknown as KernelFunc,\n};\n"],"mappings":"AACA;;;;;;;;;;;;;;;;AAiBA,SAAQA,GAAG,EAAEC,cAAc,EAAmFC,IAAI,QAAO,uBAAuB;AAGhJ,SAAQC,gBAAgB,QAAO,kBAAkB;AACjD,SAAQC,sBAAsB,QAAO,yBAAyB;AAE9D,OAAO,MAAMC,SAAS,GAIHA,CAAC;EAACC,MAAM;EAAEC,OAAO;EAAEC;AAAK,CAAC,KAAI;EAC9C,MAAM;IAACC,CAAC;IAAEC,IAAI;IAAEC,QAAQ;IAAEC,MAAM;IAAEC;EAAK,CAAC,GAAGP,MAAM;EAEjDJ,IAAI,CAACY,MAAM,CACPJ,IAAI,CAACK,KAAK,CAACC,MAAM,KAAKL,QAAQ,CAACI,KAAK,CAACC,MAAM,EAC3C,MAAM,kEAAkE,GACpE,cAAc,CAAC;EACvBd,IAAI,CAACY,MAAM,CACPF,MAAM,IAAI,IAAI,IAAIF,IAAI,CAACK,KAAK,CAACC,MAAM,KAAKJ,MAAM,CAACG,KAAK,CAACC,MAAM,EAC3D,MAAM,gEAAgE,GAClE,cAAc,CAAC;EACvBd,IAAI,CAACY,MAAM,CACPD,KAAK,IAAI,IAAI,IAAIH,IAAI,CAACK,KAAK,CAACC,MAAM,KAAKH,KAAK,CAACE,KAAK,CAACC,MAAM,EACzD,MAAM,+DAA+D,GACjE,cAAc,CAAC;EAEvB,IAAI;IAACC;EAAe,CAAC,GAAGT,KAAK;EAC7B,IAAIS,eAAe,IAAI,IAAI,EAAE;IAC3BA,eAAe,GAAG,KAAK;;EAGzB,MAAMC,WAAW,GAAG,CAACT,CAAC,EAAEC,IAAI,EAAEC,QAAQ,CAAC;EAEvC,IAAIQ,WAAW,GAAG,IAAI;EACtB,IAAIP,MAAM,IAAI,IAAI,EAAE;IAClBO,WAAW,GAAGP,MAAM,CAACG,KAAK;IAC1BG,WAAW,CAACE,IAAI,CAACR,MAAM,CAAC;;EAG1B,IAAIS,UAAU,GAAG,IAAI;EACrB,IAAIR,KAAK,IAAI,IAAI,EAAE;IACjBQ,UAAU,GAAGR,KAAK,CAACE,KAAK;IACxBG,WAAW,CAACE,IAAI,CAACP,KAAK,CAAC;;EAGzB,MAAMS,OAAO,GAAGtB,GAAG,EAAE,CAACuB,OAAO,CAAC,0BAA0B,CAAC,GACrD,IAAInB,sBAAsB,CACtBK,CAAC,CAACM,KAAK,EAAEL,IAAI,CAACK,KAAK,EAAEJ,QAAQ,CAACI,KAAK,EAAEI,WAAW,EAAEE,UAAU,EAC5DJ,eAAe,CAAC,GACpB,IAAId,gBAAgB,CAChBM,CAAC,CAACM,KAAK,EAAEL,IAAI,CAACK,KAAK,EAAEJ,QAAQ,CAACI,KAAK,EAAEI,WAAW,EAAEE,UAAU,EAC5DJ,eAAe,CAAC;EACxB,MAAMO,MAAM,GACRjB,OAAO,CAACkB,eAAe,CAACH,OAAO,EAAEJ,WAAW,EAAEA,WAAW,CAAC,CAAC,CAAC,CAACQ,KAAK,CAAC;EAEvE,OAAOF,MAAM;AACf,CAAC;AAED,OAAO,MAAMG,eAAe,GAAiB;EAC3CC,UAAU,EAAE3B,cAAc;EAC1B4B,WAAW,EAAE,OAAO;EACpBC,UAAU,EAAEzB;CACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}