{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { keep, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { mul } from '../ops/mul';\nimport { scalar } from '../ops/scalar';\nimport { Optimizer } from './optimizer';\n/** @doclink Optimizer */\nexport class SGDOptimizer extends Optimizer {\n  /** @nocollapse */\n  static get className() {\n    // Name matters for Python compatibility.\n    // This is a getter instead of a property because when it's a property, it\n    // prevents the entire class from being tree-shaken.\n    return 'SGD';\n  }\n  constructor(learningRate) {\n    super();\n    this.learningRate = learningRate;\n    this.setLearningRate(learningRate);\n  }\n  applyGradients(variableGradients) {\n    const varNames = Array.isArray(variableGradients) ? variableGradients.map(v => v.name) : Object.keys(variableGradients);\n    varNames.forEach((name, i) => {\n      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n      const value = ENGINE.registeredVariables[name];\n      tidy(() => {\n        const newValue = add(mul(this.c, gradient), value);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n  /**\n   * Sets the learning rate of the optimizer.\n   */\n  setLearningRate(learningRate) {\n    this.learningRate = learningRate;\n    if (this.c != null) {\n      this.c.dispose();\n    }\n    this.c = keep(scalar(-learningRate));\n  }\n  dispose() {\n    this.c.dispose();\n  }\n  async getWeights() {\n    return [await this.saveIterations()];\n  }\n  async setWeights(weightValues) {\n    weightValues = await this.extractIterations(weightValues);\n    if (weightValues.length !== 0) {\n      throw new Error('SGD optimizer does not have settable weights.');\n    }\n  }\n  getConfig() {\n    return {\n      'learningRate': this.learningRate\n    };\n  }\n  /** @nocollapse */\n  static fromConfig(cls, config) {\n    return new cls(config['learningRate']);\n  }\n}","map":{"version":3,"names":["ENGINE","keep","tidy","add","mul","scalar","Optimizer","SGDOptimizer","className","constructor","learningRate","setLearningRate","applyGradients","variableGradients","varNames","Array","isArray","map","v","name","Object","keys","forEach","i","gradient","tensor","value","registeredVariables","newValue","c","assign","incrementIterations","dispose","getWeights","saveIterations","setWeights","weightValues","extractIterations","length","Error","getConfig","fromConfig","cls","config"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-core/src/optimizers/sgd_optimizer.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {keep, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {mul} from '../ops/mul';\nimport {scalar} from '../ops/scalar';\nimport {ConfigDict, Serializable, SerializableConstructor} from '../serialization';\nimport {Scalar} from '../tensor';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\n\nimport {Optimizer} from './optimizer';\n\n/** @doclink Optimizer */\nexport class SGDOptimizer extends Optimizer {\n  /** @nocollapse */\n  static get className() {\n    // Name matters for Python compatibility.\n    // This is a getter instead of a property because when it's a property, it\n    // prevents the entire class from being tree-shaken.\n    return 'SGD';\n  }\n  protected c: Scalar;\n\n  constructor(protected learningRate: number) {\n    super();\n    this.setLearningRate(learningRate);\n  }\n\n  applyGradients(variableGradients: NamedTensorMap|NamedTensor[]) {\n    const varNames = Array.isArray(variableGradients) ?\n        variableGradients.map(v => v.name) :\n        Object.keys(variableGradients);\n    varNames.forEach((name, i) => {\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n      const value = ENGINE.registeredVariables[name];\n      tidy(() => {\n        const newValue = add(mul(this.c, gradient), value);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n\n  /**\n   * Sets the learning rate of the optimizer.\n   */\n  setLearningRate(learningRate: number) {\n    this.learningRate = learningRate;\n    if (this.c != null) {\n      this.c.dispose();\n    }\n    this.c = keep(scalar(-learningRate));\n  }\n\n  override dispose() {\n    this.c.dispose();\n  }\n\n  override async getWeights(): Promise<NamedTensor[]> {\n    return [await this.saveIterations()];\n  }\n\n  override async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    if (weightValues.length !== 0) {\n      throw new Error('SGD optimizer does not have settable weights.');\n    }\n  }\n\n  getConfig(): ConfigDict {\n    return {'learningRate': this.learningRate};\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(config['learningRate']);\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,MAAM,QAAO,WAAW;AAChC,SAAQC,IAAI,EAAEC,IAAI,QAAO,YAAY;AACrC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,MAAM,QAAO,eAAe;AAKpC,SAAQC,SAAS,QAAO,aAAa;AAErC;AACA,OAAM,MAAOC,YAAa,SAAQD,SAAS;EACzC;EACA,WAAWE,SAASA,CAAA;IAClB;IACA;IACA;IACA,OAAO,KAAK;EACd;EAGAC,YAAsBC,YAAoB;IACxC,KAAK,EAAE;IADa,KAAAA,YAAY,GAAZA,YAAY;IAEhC,IAAI,CAACC,eAAe,CAACD,YAAY,CAAC;EACpC;EAEAE,cAAcA,CAACC,iBAA+C;IAC5D,MAAMC,QAAQ,GAAGC,KAAK,CAACC,OAAO,CAACH,iBAAiB,CAAC,GAC7CA,iBAAiB,CAACI,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACC,IAAI,CAAC,GAClCC,MAAM,CAACC,IAAI,CAACR,iBAAiB,CAAC;IAClCC,QAAQ,CAACQ,OAAO,CAAC,CAACH,IAAI,EAAEI,CAAC,KAAI;MAC3B,MAAMC,QAAQ,GAAGT,KAAK,CAACC,OAAO,CAACH,iBAAiB,CAAC,GAC7CA,iBAAiB,CAACU,CAAC,CAAC,CAACE,MAAM,GAC3BZ,iBAAiB,CAACM,IAAI,CAAC;MAC3B,IAAIK,QAAQ,IAAI,IAAI,EAAE;QACpB;;MAEF,MAAME,KAAK,GAAG1B,MAAM,CAAC2B,mBAAmB,CAACR,IAAI,CAAC;MAC9CjB,IAAI,CAAC,MAAK;QACR,MAAM0B,QAAQ,GAAGzB,GAAG,CAACC,GAAG,CAAC,IAAI,CAACyB,CAAC,EAAEL,QAAQ,CAAC,EAAEE,KAAK,CAAC;QAClDA,KAAK,CAACI,MAAM,CAACF,QAAQ,CAAC;MACxB,CAAC,CAAC;IACJ,CAAC,CAAC;IACF,IAAI,CAACG,mBAAmB,EAAE;EAC5B;EAEA;;;EAGApB,eAAeA,CAACD,YAAoB;IAClC,IAAI,CAACA,YAAY,GAAGA,YAAY;IAChC,IAAI,IAAI,CAACmB,CAAC,IAAI,IAAI,EAAE;MAClB,IAAI,CAACA,CAAC,CAACG,OAAO,EAAE;;IAElB,IAAI,CAACH,CAAC,GAAG5B,IAAI,CAACI,MAAM,CAAC,CAACK,YAAY,CAAC,CAAC;EACtC;EAESsB,OAAOA,CAAA;IACd,IAAI,CAACH,CAAC,CAACG,OAAO,EAAE;EAClB;EAES,MAAMC,UAAUA,CAAA;IACvB,OAAO,CAAC,MAAM,IAAI,CAACC,cAAc,EAAE,CAAC;EACtC;EAES,MAAMC,UAAUA,CAACC,YAA2B;IACnDA,YAAY,GAAG,MAAM,IAAI,CAACC,iBAAiB,CAACD,YAAY,CAAC;IACzD,IAAIA,YAAY,CAACE,MAAM,KAAK,CAAC,EAAE;MAC7B,MAAM,IAAIC,KAAK,CAAC,+CAA+C,CAAC;;EAEpE;EAEAC,SAASA,CAAA;IACP,OAAO;MAAC,cAAc,EAAE,IAAI,CAAC9B;IAAY,CAAC;EAC5C;EAEA;EACA,OAAgB+B,UAAUA,CACtBC,GAA+B,EAAEC,MAAkB;IACrD,OAAO,IAAID,GAAG,CAACC,MAAM,CAAC,cAAc,CAAC,CAAC;EACxC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}