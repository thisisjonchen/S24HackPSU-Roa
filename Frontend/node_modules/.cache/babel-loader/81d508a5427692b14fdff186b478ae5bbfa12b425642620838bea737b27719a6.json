{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Softmax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction softmax_(logits, dim = -1) {\n  const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n  if (dim === -1) {\n    dim = $logits.rank - 1;\n  }\n  if (dim !== $logits.rank - 1) {\n    throw Error('Softmax along a non-last dimension is not yet supported. ' + `Logits was rank ${$logits.rank} and dim was ${dim}`);\n  }\n  const inputs = {\n    logits: $logits\n  };\n  const attrs = {\n    dim\n  };\n  return ENGINE.runKernel(Softmax, inputs, attrs);\n}\nexport const softmax = /* @__PURE__ */op({\n  softmax_\n});","map":{"version":3,"names":["ENGINE","Softmax","convertToTensor","op","softmax_","logits","dim","$logits","rank","Error","inputs","attrs","runKernel","softmax"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-core/src/ops/softmax.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Softmax, SoftmaxAttrs, SoftmaxInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction softmax_<T extends Tensor>(logits: T|TensorLike, dim = -1): T {\n  const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n\n  if (dim === -1) {\n    dim = $logits.rank - 1;\n  }\n  if (dim !== $logits.rank - 1) {\n    throw Error(\n        'Softmax along a non-last dimension is not yet supported. ' +\n        `Logits was rank ${$logits.rank} and dim was ${dim}`);\n  }\n\n  const inputs: SoftmaxInputs = {logits: $logits};\n  const attrs: SoftmaxAttrs = {dim};\n\n  return ENGINE.runKernel(\n      Softmax, inputs as unknown as NamedTensorMap,\n      attrs as unknown as NamedAttrMap);\n}\n\nexport const softmax = /* @__PURE__ */ op({softmax_});\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,MAAM,QAAO,WAAW;AAChC,SAAQC,OAAO,QAAoC,iBAAiB;AAIpE,SAAQC,eAAe,QAAO,oBAAoB;AAGlD,SAAQC,EAAE,QAAO,aAAa;AAE9B;;;;;;;;;;;;;;;;;;;;;AAqBA,SAASC,QAAQA,CAAmBC,MAAoB,EAAEC,GAAG,GAAG,CAAC,CAAC;EAChE,MAAMC,OAAO,GAAGL,eAAe,CAACG,MAAM,EAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,CAAC;EAEvE,IAAIC,GAAG,KAAK,CAAC,CAAC,EAAE;IACdA,GAAG,GAAGC,OAAO,CAACC,IAAI,GAAG,CAAC;;EAExB,IAAIF,GAAG,KAAKC,OAAO,CAACC,IAAI,GAAG,CAAC,EAAE;IAC5B,MAAMC,KAAK,CACP,2DAA2D,GAC3D,mBAAmBF,OAAO,CAACC,IAAI,gBAAgBF,GAAG,EAAE,CAAC;;EAG3D,MAAMI,MAAM,GAAkB;IAACL,MAAM,EAAEE;EAAO,CAAC;EAC/C,MAAMI,KAAK,GAAiB;IAACL;EAAG,CAAC;EAEjC,OAAON,MAAM,CAACY,SAAS,CACnBX,OAAO,EAAES,MAAmC,EAC5CC,KAAgC,CAAC;AACvC;AAEA,OAAO,MAAME,OAAO,GAAG,eAAgBV,EAAE,CAAC;EAACC;AAAQ,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}