{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, Slice, slice_util, util } from '@tensorflow/tfjs-core';\nimport { sliceImplCPU } from '../kernel_utils/shared';\nimport { SliceProgram } from '../slice_gpu';\nimport { SlicePackedProgram } from '../slice_packed_gpu';\nfunction shallowSlice(x, begin, size, backend) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId);\n  // Copy texture data from the original tensor.\n  Object.assign(newTexData, xTexData);\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset = slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  };\n  // Increase the ref count for that data bucket.\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\nexport function slice(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    begin,\n    size\n  } = attrs;\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n  const {\n    isPacked\n  } = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ? new SlicePackedProgram($size) : new SliceProgram($size);\n    const customValues = [$begin];\n    return backend.runWebGLProgram(program, [x], x.dtype, customValues);\n  }\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\nexport const sliceConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice\n};","map":{"version":3,"names":["env","Slice","slice_util","util","sliceImplCPU","SliceProgram","SlicePackedProgram","shallowSlice","x","begin","size","backend","xTexData","texData","get","dataId","t","makeTensorInfo","dtype","newTexData","Object","assign","refCount","shape","flatOffset","computeFlatOffset","computeStrides","slice","origDataId","dataRefCount","set","args","inputs","attrs","$begin","$size","parseSliceParams","assertParamsValid","sizeFromShape","shouldExecuteOnCPU","outValues","values","isPacked","isContinous","isSliceContinous","program","getBool","customValues","runWebGLProgram","uploadToGPU","sliceConfig","kernelName","backendName","kernelFunc"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-backend-webgl/src/kernels/Slice.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {sliceImplCPU} from '../kernel_utils/shared';\nimport {SliceProgram} from '../slice_gpu';\nimport {SlicePackedProgram} from '../slice_packed_gpu';\n\nfunction shallowSlice(\n    x: TensorInfo, begin: number[], size: number[], backend: MathBackendWebGL) {\n  const xTexData = backend.texData.get(x.dataId);\n  const t = backend.makeTensorInfo(size, x.dtype);\n  const newTexData = backend.texData.get(t.dataId);\n  // Copy texture data from the original tensor.\n  Object.assign(newTexData, xTexData);\n  newTexData.refCount = 1;\n  newTexData.shape = size;\n  newTexData.dtype = x.dtype;\n  let flatOffset =\n      slice_util.computeFlatOffset(begin, util.computeStrides(x.shape));\n  if (xTexData.slice) {\n    // We are slicing an already sliced tensor, so we have to accumulate\n    // the offset.\n    flatOffset += xTexData.slice.flatOffset;\n  }\n  newTexData.slice = {\n    flatOffset,\n    // Point to the original dataId, which is used to do ref counting.\n    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n  };\n\n  // Increase the ref count for that data bucket.\n  const refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;\n  backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n  return t;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendWebGL, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  if (util.sizeFromShape($size) === 0) {\n    return backend.makeTensorInfo($size, x.dtype, []);\n  }\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgl doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {\n    const xTexData = backend.texData.get(x.dataId);\n    const outValues = sliceImplCPU(\n        xTexData.values as TypedArray, $begin, $size, x.shape, x.dtype);\n    return backend.makeTensorInfo($size, x.dtype, outValues);\n  }\n\n  const {isPacked} = backend.texData.get(x.dataId);\n  const isContinous = slice_util.isSliceContinous(x.shape, $begin, $size);\n  if (isPacked || !isContinous) {\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n        new SlicePackedProgram($size) :\n        new SliceProgram($size);\n    const customValues = [$begin];\n    return backend.runWebGLProgram(program, [x], x.dtype, customValues);\n  }\n  backend.uploadToGPU(x.dataId);\n  return shallowSlice(x, $begin, $size, backend);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'webgl',\n  kernelFunc: slice as unknown as KernelFunc\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,GAAG,EAA4BC,KAAK,EAAEC,UAAU,EAAmDC,IAAI,QAAO,uBAAuB;AAG7I,SAAQC,YAAY,QAAO,wBAAwB;AACnD,SAAQC,YAAY,QAAO,cAAc;AACzC,SAAQC,kBAAkB,QAAO,qBAAqB;AAEtD,SAASC,YAAYA,CACjBC,CAAa,EAAEC,KAAe,EAAEC,IAAc,EAAEC,OAAyB;EAC3E,MAAMC,QAAQ,GAAGD,OAAO,CAACE,OAAO,CAACC,GAAG,CAACN,CAAC,CAACO,MAAM,CAAC;EAC9C,MAAMC,CAAC,GAAGL,OAAO,CAACM,cAAc,CAACP,IAAI,EAAEF,CAAC,CAACU,KAAK,CAAC;EAC/C,MAAMC,UAAU,GAAGR,OAAO,CAACE,OAAO,CAACC,GAAG,CAACE,CAAC,CAACD,MAAM,CAAC;EAChD;EACAK,MAAM,CAACC,MAAM,CAACF,UAAU,EAAEP,QAAQ,CAAC;EACnCO,UAAU,CAACG,QAAQ,GAAG,CAAC;EACvBH,UAAU,CAACI,KAAK,GAAGb,IAAI;EACvBS,UAAU,CAACD,KAAK,GAAGV,CAAC,CAACU,KAAK;EAC1B,IAAIM,UAAU,GACVtB,UAAU,CAACuB,iBAAiB,CAAChB,KAAK,EAAEN,IAAI,CAACuB,cAAc,CAAClB,CAAC,CAACe,KAAK,CAAC,CAAC;EACrE,IAAIX,QAAQ,CAACe,KAAK,EAAE;IAClB;IACA;IACAH,UAAU,IAAIZ,QAAQ,CAACe,KAAK,CAACH,UAAU;;EAEzCL,UAAU,CAACQ,KAAK,GAAG;IACjBH,UAAU;IACV;IACAI,UAAU,EAAEhB,QAAQ,CAACe,KAAK,IAAIf,QAAQ,CAACe,KAAK,CAACC,UAAU,IAAIpB,CAAC,CAACO;GAC9D;EAED;EACA,MAAMO,QAAQ,GAAGX,OAAO,CAACkB,YAAY,CAACf,GAAG,CAACK,UAAU,CAACQ,KAAK,CAACC,UAAU,CAAC,IAAI,CAAC;EAC3EjB,OAAO,CAACkB,YAAY,CAACC,GAAG,CAACX,UAAU,CAACQ,KAAK,CAACC,UAAU,EAAEN,QAAQ,GAAG,CAAC,CAAC;EACnE,OAAON,CAAC;AACV;AAEA,OAAM,SAAUW,KAAKA,CACjBI,IAAyE;EAE3E,MAAM;IAACC,MAAM;IAAErB,OAAO;IAAEsB;EAAK,CAAC,GAAGF,IAAI;EACrC,MAAM;IAACvB;EAAC,CAAC,GAAGwB,MAAM;EAClB,MAAM;IAACvB,KAAK;IAAEC;EAAI,CAAC,GAAGuB,KAAK;EAE3B,MAAM,CAACC,MAAM,EAAEC,KAAK,CAAC,GAAGjC,UAAU,CAACkC,gBAAgB,CAAC5B,CAAC,EAAEC,KAAK,EAAEC,IAAI,CAAC;EACnER,UAAU,CAACmC,iBAAiB,CAAC7B,CAAC,EAAE0B,MAAM,EAAEC,KAAK,CAAC;EAE9C,IAAIhC,IAAI,CAACmC,aAAa,CAACH,KAAK,CAAC,KAAK,CAAC,EAAE;IACnC,OAAOxB,OAAO,CAACM,cAAc,CAACkB,KAAK,EAAE3B,CAAC,CAACU,KAAK,EAAE,EAAE,CAAC;;EAGnD;EACA;EACA;EACA;EACA;EACA;EACA,IAAIP,OAAO,CAAC4B,kBAAkB,CAAC,CAAC/B,CAAC,CAAC,CAAC,IAAIA,CAAC,CAACU,KAAK,KAAK,QAAQ,EAAE;IAC3D,MAAMN,QAAQ,GAAGD,OAAO,CAACE,OAAO,CAACC,GAAG,CAACN,CAAC,CAACO,MAAM,CAAC;IAC9C,MAAMyB,SAAS,GAAGpC,YAAY,CAC1BQ,QAAQ,CAAC6B,MAAoB,EAAEP,MAAM,EAAEC,KAAK,EAAE3B,CAAC,CAACe,KAAK,EAAEf,CAAC,CAACU,KAAK,CAAC;IACnE,OAAOP,OAAO,CAACM,cAAc,CAACkB,KAAK,EAAE3B,CAAC,CAACU,KAAK,EAAEsB,SAAS,CAAC;;EAG1D,MAAM;IAACE;EAAQ,CAAC,GAAG/B,OAAO,CAACE,OAAO,CAACC,GAAG,CAACN,CAAC,CAACO,MAAM,CAAC;EAChD,MAAM4B,WAAW,GAAGzC,UAAU,CAAC0C,gBAAgB,CAACpC,CAAC,CAACe,KAAK,EAAEW,MAAM,EAAEC,KAAK,CAAC;EACvE,IAAIO,QAAQ,IAAI,CAACC,WAAW,EAAE;IAC5B,MAAME,OAAO,GAAG7C,GAAG,EAAE,CAAC8C,OAAO,CAAC,6BAA6B,CAAC,GACxD,IAAIxC,kBAAkB,CAAC6B,KAAK,CAAC,GAC7B,IAAI9B,YAAY,CAAC8B,KAAK,CAAC;IAC3B,MAAMY,YAAY,GAAG,CAACb,MAAM,CAAC;IAC7B,OAAOvB,OAAO,CAACqC,eAAe,CAACH,OAAO,EAAE,CAACrC,CAAC,CAAC,EAAEA,CAAC,CAACU,KAAK,EAAE6B,YAAY,CAAC;;EAErEpC,OAAO,CAACsC,WAAW,CAACzC,CAAC,CAACO,MAAM,CAAC;EAC7B,OAAOR,YAAY,CAACC,CAAC,EAAE0B,MAAM,EAAEC,KAAK,EAAExB,OAAO,CAAC;AAChD;AAEA,OAAO,MAAMuC,WAAW,GAAiB;EACvCC,UAAU,EAAElD,KAAK;EACjBmD,WAAW,EAAE,OAAO;EACpBC,UAAU,EAAE1B;CACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}