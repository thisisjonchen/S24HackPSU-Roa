{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, FusedConv2D, util } from '@tensorflow/tfjs-core';\nimport { Conv2DProgram } from '../conv_gpu';\nimport { Conv2DPackedProgram } from '../conv_packed_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { conv2dByMatMul, conv2dWithIm2Row } from './Conv2D_impl';\nimport { reshape } from './Reshape';\nexport function fusedConv2d(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x,\n    filter,\n    bias,\n    preluActivationWeights\n  } = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n  let out;\n  const intermediates = [];\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  const prepareInputs = () => {\n    const inputs = [x, filter];\n    // If the input is a 1-D tensor, align it with the channels.\n    //\n    // For fusedConv2d, the inputs (x, W, bias, preluActivationWeights) are\n    // supposed to be aligned with the dataFormat. The 4-D tensor inputs or\n    // scalar inputs are originally aligned, but the 1-D tensor inputs are\n    // supposed to be aligned with the channels (only bias and PReLU activation\n    // weights could be a 1-D tensor).\n    const alignInputWithDataFormat = (input, dataFormat) => {\n      if (dataFormat === 'NCHW' && input.shape.length === 1 && input.shape[0] !== 1) {\n        const alignedInput = reshape({\n          inputs: {\n            x: input\n          },\n          backend,\n          attrs: {\n            shape: [input.shape[0], 1, 1]\n          }\n        });\n        intermediates.push(alignedInput);\n        return alignedInput;\n      }\n      return input;\n    };\n    if (hasBias) {\n      inputs.push(alignInputWithDataFormat(bias, dataFormat));\n    }\n    if (hasPreluActivationWeights) {\n      inputs.push(alignInputWithDataFormat(preluActivationWeights, dataFormat));\n    }\n    if (hasLeakyreluAlpha) {\n      const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n      inputs.push($leakyreluAlpha);\n      intermediates.push($leakyreluAlpha);\n    }\n    return inputs;\n  };\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n    out = conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else if (convInfo.strideWidth <= 2 && $dataFormat === 'channelsLast' && env().getBool('WEBGL_EXP_CONV')) {\n    const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n    const program = new Conv2DPackedProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    const customValues = [[convInfo.padInfo.top, convInfo.padInfo.left], [convInfo.strideHeight, convInfo.strideWidth], [convInfo.dilationHeight, convInfo.dilationWidth], [convInfo.inHeight, convInfo.inWidth]];\n    const inputs = prepareInputs();\n    out = backend.runWebGLProgram(program, inputs, 'float32', customValues);\n  } else if (env().getBool('WEBGL_CONV_IM2COL')) {\n    out = conv2dWithIm2Row({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else {\n    const fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;\n    const program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    const inputs = prepareInputs();\n    out = backend.runWebGLProgram(program, inputs, 'float32');\n  }\n  const outReshaped = reshape({\n    inputs: {\n      x: out\n    },\n    backend,\n    attrs: {\n      shape: convInfo.outShape\n    }\n  });\n  intermediates.push(out);\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n  return outReshaped;\n}\nexport const fusedConv2DConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgl',\n  kernelFunc: fusedConv2d\n};","map":{"version":3,"names":["backend_util","env","FusedConv2D","util","Conv2DProgram","Conv2DPackedProgram","mapActivationToShaderProgram","conv2dByMatMul","conv2dWithIm2Row","reshape","fusedConv2d","args","inputs","backend","attrs","x","filter","bias","preluActivationWeights","strides","pad","dataFormat","dilations","dimRoundingMode","activation","leakyreluAlpha","$dataFormat","convertConv2DDataFormat","convInfo","computeConv2DInfo","shape","out","intermediates","hasBias","hasPreluActivationWeights","hasLeakyreluAlpha","prepareInputs","alignInputWithDataFormat","input","length","alignedInput","push","$leakyreluAlpha","makeTensorInfo","createScalarValue","filterHeight","filterWidth","dilationHeight","dilationWidth","strideHeight","strideWidth","padInfo","type","getBool","fusedActivation","program","customValues","top","left","inHeight","inWidth","runWebGLProgram","outReshaped","outShape","forEach","t","disposeIntermediateTensorInfo","fusedConv2DConfig","kernelName","backendName","kernelFunc"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-backend-webgl/src/kernels/FusedConv2D.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, env, FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {Conv2DProgram} from '../conv_gpu';\nimport {Conv2DPackedProgram} from '../conv_packed_gpu';\nimport {mapActivationToShaderProgram} from '../kernel_utils/kernel_funcs_utils';\n\nimport {conv2dByMatMul, conv2dWithIm2Row} from './Conv2D_impl';\nimport {reshape} from './Reshape';\n\nexport function fusedConv2d(args: {\n  inputs: FusedConv2DInputs,\n  attrs: FusedConv2DAttrs,\n  backend: MathBackendWebGL\n}) {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n  let out: TensorInfo;\n  const intermediates: TensorInfo[] = [];\n\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n\n  const prepareInputs = (): TensorInfo[] => {\n    const inputs: TensorInfo[] = [x, filter];\n\n    // If the input is a 1-D tensor, align it with the channels.\n    //\n    // For fusedConv2d, the inputs (x, W, bias, preluActivationWeights) are\n    // supposed to be aligned with the dataFormat. The 4-D tensor inputs or\n    // scalar inputs are originally aligned, but the 1-D tensor inputs are\n    // supposed to be aligned with the channels (only bias and PReLU activation\n    // weights could be a 1-D tensor).\n    const alignInputWithDataFormat =\n        (input: TensorInfo, dataFormat: 'NHWC'|'NCHW'): TensorInfo => {\n          if (dataFormat === 'NCHW' && input.shape.length === 1 &&\n              input.shape[0] !== 1) {\n            const alignedInput = reshape({\n              inputs: {x: input},\n              backend,\n              attrs: {shape: [input.shape[0], 1, 1]}\n            });\n            intermediates.push(alignedInput);\n            return alignedInput;\n          }\n          return input;\n        };\n\n    if (hasBias) {\n      inputs.push(alignInputWithDataFormat(bias, dataFormat));\n    }\n\n    if (hasPreluActivationWeights) {\n      inputs.push(alignInputWithDataFormat(preluActivationWeights, dataFormat));\n    }\n\n    if (hasLeakyreluAlpha) {\n      const $leakyreluAlpha = backend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(leakyreluAlpha as unknown as 'float32', 'float32'));\n      inputs.push($leakyreluAlpha);\n      intermediates.push($leakyreluAlpha);\n    }\n    return inputs;\n  };\n\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n      convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n      convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n      (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n    out = conv2dByMatMul({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else if (convInfo.strideWidth <= 2 && $dataFormat === 'channelsLast'\n    && env().getBool('WEBGL_EXP_CONV')\n    ) {\n      const fusedActivation =\n          activation ? mapActivationToShaderProgram(activation, true) : null;\n    const program = new Conv2DPackedProgram(\n      convInfo, hasBias, fusedActivation, hasPreluActivationWeights,\n      hasLeakyreluAlpha);\n    const customValues = [\n      [convInfo.padInfo.top, convInfo.padInfo.left],\n      [convInfo.strideHeight, convInfo.strideWidth],\n      [convInfo.dilationHeight, convInfo.dilationWidth],\n      [convInfo.inHeight, convInfo.inWidth]\n    ];\n    const inputs = prepareInputs();\n    out = backend.runWebGLProgram(program, inputs, 'float32', customValues);\n  } else if (env().getBool('WEBGL_CONV_IM2COL')) {\n    out = conv2dWithIm2Row({\n      x,\n      filter,\n      convInfo,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n  } else {\n    const fusedActivation =\n        activation ? mapActivationToShaderProgram(activation, false) : null;\n    const program = new Conv2DProgram(\n        convInfo, hasBias, fusedActivation, hasPreluActivationWeights,\n        hasLeakyreluAlpha);\n\n    const inputs = prepareInputs();\n    out = backend.runWebGLProgram(program, inputs, 'float32');\n  }\n\n  const outReshaped =\n      reshape({inputs: {x: out}, backend, attrs: {shape: convInfo.outShape}});\n\n  intermediates.push(out);\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outReshaped;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgl',\n  kernelFunc: fusedConv2d as unknown as KernelFunc,\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,EAAEC,GAAG,EAAEC,WAAW,EAA6EC,IAAI,QAAO,uBAAuB;AAGrJ,SAAQC,aAAa,QAAO,aAAa;AACzC,SAAQC,mBAAmB,QAAO,oBAAoB;AACtD,SAAQC,4BAA4B,QAAO,oCAAoC;AAE/E,SAAQC,cAAc,EAAEC,gBAAgB,QAAO,eAAe;AAC9D,SAAQC,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAUC,WAAWA,CAACC,IAI3B;EACC,MAAM;IAACC,MAAM;IAAEC,OAAO;IAAEC;EAAK,CAAC,GAAGH,IAAI;EACrC,MAAM;IAACI,CAAC;IAAEC,MAAM;IAAEC,IAAI;IAAEC;EAAsB,CAAC,GAAGN,MAAM;EACxD,MAAM;IACJO,OAAO;IACPC,GAAG;IACHC,UAAU;IACVC,SAAS;IACTC,eAAe;IACfC,UAAU;IACVC;EAAc,CACf,GAAGX,KAAK;EAET,MAAMY,WAAW,GAAG1B,YAAY,CAAC2B,uBAAuB,CAACN,UAAU,CAAC;EACpE,MAAMO,QAAQ,GAAG5B,YAAY,CAAC6B,iBAAiB,CAC3Cd,CAAC,CAACe,KAAyC,EAC3Cd,MAAM,CAACc,KAAyC,EAAEX,OAAO,EAAEG,SAAS,EAAEF,GAAG,EACzEG,eAAe,EAAE,KAAK,CAAC,iBAAiBG,WAAW,CAAC;EACxD,IAAIK,GAAe;EACnB,MAAMC,aAAa,GAAiB,EAAE;EAEtC,MAAMC,OAAO,GAAGhB,IAAI,IAAI,IAAI;EAC5B,MAAMiB,yBAAyB,GAAGhB,sBAAsB,IAAI,IAAI;EAChE,MAAMiB,iBAAiB,GAAGX,UAAU,KAAK,WAAW;EAEpD,MAAMY,aAAa,GAAGA,CAAA,KAAmB;IACvC,MAAMxB,MAAM,GAAiB,CAACG,CAAC,EAAEC,MAAM,CAAC;IAExC;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAMqB,wBAAwB,GAC1BA,CAACC,KAAiB,EAAEjB,UAAyB,KAAgB;MAC3D,IAAIA,UAAU,KAAK,MAAM,IAAIiB,KAAK,CAACR,KAAK,CAACS,MAAM,KAAK,CAAC,IACjDD,KAAK,CAACR,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;QACxB,MAAMU,YAAY,GAAG/B,OAAO,CAAC;UAC3BG,MAAM,EAAE;YAACG,CAAC,EAAEuB;UAAK,CAAC;UAClBzB,OAAO;UACPC,KAAK,EAAE;YAACgB,KAAK,EAAE,CAACQ,KAAK,CAACR,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC;UAAC;SACtC,CAAC;QACFE,aAAa,CAACS,IAAI,CAACD,YAAY,CAAC;QAChC,OAAOA,YAAY;;MAErB,OAAOF,KAAK;IACd,CAAC;IAEL,IAAIL,OAAO,EAAE;MACXrB,MAAM,CAAC6B,IAAI,CAACJ,wBAAwB,CAACpB,IAAI,EAAEI,UAAU,CAAC,CAAC;;IAGzD,IAAIa,yBAAyB,EAAE;MAC7BtB,MAAM,CAAC6B,IAAI,CAACJ,wBAAwB,CAACnB,sBAAsB,EAAEG,UAAU,CAAC,CAAC;;IAG3E,IAAIc,iBAAiB,EAAE;MACrB,MAAMO,eAAe,GAAG7B,OAAO,CAAC8B,cAAc,CAC1C,EAAE,EAAE,SAAS,EACbxC,IAAI,CAACyC,iBAAiB,CAACnB,cAAsC,EAAE,SAAS,CAAC,CAAC;MAC9Eb,MAAM,CAAC6B,IAAI,CAACC,eAAe,CAAC;MAC5BV,aAAa,CAACS,IAAI,CAACC,eAAe,CAAC;;IAErC,OAAO9B,MAAM;EACf,CAAC;EAED,IAAIgB,QAAQ,CAACiB,YAAY,KAAK,CAAC,IAAIjB,QAAQ,CAACkB,WAAW,KAAK,CAAC,IACzDlB,QAAQ,CAACmB,cAAc,KAAK,CAAC,IAAInB,QAAQ,CAACoB,aAAa,KAAK,CAAC,IAC7DpB,QAAQ,CAACqB,YAAY,KAAK,CAAC,IAAIrB,QAAQ,CAACsB,WAAW,KAAK,CAAC,KACxDtB,QAAQ,CAACuB,OAAO,CAACC,IAAI,KAAK,MAAM,IAAIxB,QAAQ,CAACuB,OAAO,CAACC,IAAI,KAAK,OAAO,CAAC,EAAE;IAC3ErB,GAAG,GAAGxB,cAAc,CAAC;MACnBQ,CAAC;MACDC,MAAM;MACNY,QAAQ;MACRf,OAAO;MACPI,IAAI;MACJO,UAAU;MACVN,sBAAsB;MACtBO;KACD,CAAC;GACH,MAAM,IAAIG,QAAQ,CAACsB,WAAW,IAAI,CAAC,IAAIxB,WAAW,KAAK,cAAc,IACjEzB,GAAG,EAAE,CAACoD,OAAO,CAAC,gBAAgB,CAAC,EAChC;IACA,MAAMC,eAAe,GACjB9B,UAAU,GAAGlB,4BAA4B,CAACkB,UAAU,EAAE,IAAI,CAAC,GAAG,IAAI;IACxE,MAAM+B,OAAO,GAAG,IAAIlD,mBAAmB,CACrCuB,QAAQ,EAAEK,OAAO,EAAEqB,eAAe,EAAEpB,yBAAyB,EAC7DC,iBAAiB,CAAC;IACpB,MAAMqB,YAAY,GAAG,CACnB,CAAC5B,QAAQ,CAACuB,OAAO,CAACM,GAAG,EAAE7B,QAAQ,CAACuB,OAAO,CAACO,IAAI,CAAC,EAC7C,CAAC9B,QAAQ,CAACqB,YAAY,EAAErB,QAAQ,CAACsB,WAAW,CAAC,EAC7C,CAACtB,QAAQ,CAACmB,cAAc,EAAEnB,QAAQ,CAACoB,aAAa,CAAC,EACjD,CAACpB,QAAQ,CAAC+B,QAAQ,EAAE/B,QAAQ,CAACgC,OAAO,CAAC,CACtC;IACD,MAAMhD,MAAM,GAAGwB,aAAa,EAAE;IAC9BL,GAAG,GAAGlB,OAAO,CAACgD,eAAe,CAACN,OAAO,EAAE3C,MAAM,EAAE,SAAS,EAAE4C,YAAY,CAAC;GACxE,MAAM,IAAIvD,GAAG,EAAE,CAACoD,OAAO,CAAC,mBAAmB,CAAC,EAAE;IAC7CtB,GAAG,GAAGvB,gBAAgB,CAAC;MACrBO,CAAC;MACDC,MAAM;MACNY,QAAQ;MACRf,OAAO;MACPI,IAAI;MACJO,UAAU;MACVN,sBAAsB;MACtBO;KACD,CAAC;GACH,MAAM;IACL,MAAM6B,eAAe,GACjB9B,UAAU,GAAGlB,4BAA4B,CAACkB,UAAU,EAAE,KAAK,CAAC,GAAG,IAAI;IACvE,MAAM+B,OAAO,GAAG,IAAInD,aAAa,CAC7BwB,QAAQ,EAAEK,OAAO,EAAEqB,eAAe,EAAEpB,yBAAyB,EAC7DC,iBAAiB,CAAC;IAEtB,MAAMvB,MAAM,GAAGwB,aAAa,EAAE;IAC9BL,GAAG,GAAGlB,OAAO,CAACgD,eAAe,CAACN,OAAO,EAAE3C,MAAM,EAAE,SAAS,CAAC;;EAG3D,MAAMkD,WAAW,GACbrD,OAAO,CAAC;IAACG,MAAM,EAAE;MAACG,CAAC,EAAEgB;IAAG,CAAC;IAAElB,OAAO;IAAEC,KAAK,EAAE;MAACgB,KAAK,EAAEF,QAAQ,CAACmC;IAAQ;EAAC,CAAC,CAAC;EAE3E/B,aAAa,CAACS,IAAI,CAACV,GAAG,CAAC;EACvBC,aAAa,CAACgC,OAAO,CAACC,CAAC,IAAIpD,OAAO,CAACqD,6BAA6B,CAACD,CAAC,CAAC,CAAC;EAEpE,OAAOH,WAAW;AACpB;AAEA,OAAO,MAAMK,iBAAiB,GAAiB;EAC7CC,UAAU,EAAElE,WAAW;EACvBmE,WAAW,EAAE,OAAO;EACpBC,UAAU,EAAE5D;CACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}