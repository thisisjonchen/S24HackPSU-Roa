{"ast":null,"code":"/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Workaround for: https://github.com/bazelbuild/rules_nodejs/issues/1265\n/// <reference types=\"@webgpu/types/dist\" />\nimport { getGlobal } from './global_util';\nimport { tensorToString } from './tensor_format';\nimport * as util from './util';\nimport { computeStrides, toNestedArray } from './util';\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class TensorBuffer {\n  constructor(shape, dtype, values) {\n    this.dtype = dtype;\n    this.shape = shape.slice();\n    this.size = util.sizeFromShape(shape);\n    if (values != null) {\n      const n = values.length;\n      util.assert(n === this.size, () => `Length of values '${n}' does not match the size ` + `inferred by the shape '${this.size}'.`);\n    }\n    if (dtype === 'complex64') {\n      throw new Error(`complex64 dtype TensorBuffers are not supported. Please create ` + `a TensorBuffer for the real and imaginary parts separately and ` + `call tf.complex(real, imag).`);\n    }\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  set(value, ...locs) {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    util.assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must ` + `match the rank (${this.rank})`);\n    const index = this.locToIndex(locs);\n    this.values[index] = value;\n  }\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  get(...locs) {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    let i = 0;\n    for (const loc of locs) {\n      if (loc < 0 || loc >= this.shape[i]) {\n        const msg = `Requested out of range element at ${locs}. ` + `  Buffer shape=${this.shape}`;\n        throw new Error(msg);\n      }\n      i++;\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return this.values[index];\n  }\n  locToIndex(locs) {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return index;\n  }\n  indexToLoc(index) {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n    const locs = new Array(this.shape.length);\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n  get rank() {\n    return this.shape.length;\n  }\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  toTensor() {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype);\n  }\n}\n// For tracking tensor creation and disposal.\nlet trackerFn = null;\n// Used by chaining methods to call into ops.\nlet opHandler = null;\n// Used to warn about deprecated methods.\nlet deprecationWarningFn = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nexport function setTensorTracker(fn) {\n  trackerFn = fn;\n}\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\nexport function setOpHandler(handler) {\n  opHandler = handler;\n}\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nexport function setDeprecationWarningFn(fn) {\n  deprecationWarningFn = fn;\n}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Tensor {\n  constructor(shape, dtype, dataId, id) {\n    /** Whether this tensor has been globally kept. */\n    this.kept = false;\n    this.isDisposedInternal = false;\n    this.shape = shape.slice();\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = this.rank < 5 ? this.rank.toString() : 'higher';\n  }\n  get rank() {\n    return this.shape.length;\n  }\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async buffer() {\n    const vals = await this.data();\n    return opHandler.buffer(this.shape, this.dtype, vals);\n  }\n  /**\n   * Returns a `tf.TensorBuffer` that holds the underlying data.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  bufferSync() {\n    return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n  }\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async array() {\n    const vals = await this.data();\n    return toNestedArray(this.shape, vals, this.dtype === 'complex64');\n  }\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  arraySync() {\n    return toNestedArray(this.shape, this.dataSync(), this.dtype === 'complex64');\n  }\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async data() {\n    this.throwIfDisposed();\n    const data = trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      const bytes = await data;\n      try {\n        return bytes.map(b => util.decodeString(b));\n      } catch (_a) {\n        throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data;\n  }\n  /**\n   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n   * and `data()`, this method prevents data from being downloaded to CPU.\n   *\n   * For WebGL backend, the data will be stored on a densely packed texture.\n   * This means that the texture will use the RGBA channels to store value.\n   *\n   * For WebGPU backend, the data will be stored on a buffer. There is no\n   * parameter, so can not use a user-defined size to create the buffer.\n   *\n   * @param options:\n   *     For WebGL,\n   *         - customTexShape: Optional. If set, will use the user defined\n   *     texture shape to create the texture.\n   *\n   * @returns For WebGL backend, a GPUData contains the new texture and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this texture,\n   *        texture: WebGLTexture,\n   *        texShape: [number, number] // [height, width]\n   *     }\n   *\n   *     For WebGPU backend, a GPUData contains the new buffer.\n   *     {\n   *        tensorRef: The tensor that is associated with this buffer,\n   *        buffer: GPUBuffer,\n   *     }\n   *\n   *     Remember to dispose the GPUData after it is used by\n   *     `res.tensorRef.dispose()`.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataToGPU(options) {\n    this.throwIfDisposed();\n    return trackerFn().readToGPU(this.dataId, options);\n  }\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataSync() {\n    this.throwIfDisposed();\n    const data = trackerFn().readSync(this.dataId);\n    if (this.dtype === 'string') {\n      try {\n        return data.map(b => util.decodeString(b));\n      } catch (_a) {\n        throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data;\n  }\n  /** Returns the underlying bytes of the tensor's data. */\n  async bytes() {\n    this.throwIfDisposed();\n    const data = await trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      return data;\n    } else {\n      return new Uint8Array(data.buffer);\n    }\n  }\n  /**\n   * Disposes `tf.Tensor` from memory.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dispose() {\n    if (this.isDisposed) {\n      return;\n    }\n    if (this.kerasMask) {\n      this.kerasMask.dispose();\n    }\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n  get isDisposed() {\n    return this.isDisposedInternal;\n  }\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  print(verbose = false) {\n    return opHandler.print(this, verbose);\n  }\n  /**\n   * Returns a copy of the tensor. See `tf.clone` for details.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  clone() {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  }\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  toString(verbose = false) {\n    const vals = this.dataSync();\n    return tensorToString(vals, this.shape, this.dtype, verbose);\n  }\n  cast(dtype) {\n    this.throwIfDisposed();\n    return opHandler.cast(this, dtype);\n  }\n  variable(trainable = true, name, dtype) {\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype);\n  }\n}\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: instance => {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;\n  }\n});\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', () => {\n    return Tensor;\n  });\n}\n// Global side effect. Cache global reference to Tensor class\ngetGlobalTensorClass();\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Variable extends Tensor {\n  constructor(initialValue, trainable, name, tensorId) {\n    super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    this.trainable = trainable;\n    this.name = name;\n  }\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  assign(newValue) {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(`dtype of the new value (${newValue.dtype}) and ` + `previous value (${this.dtype}) must match`);\n    }\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(`shape of the new value (${newValue.shape}) and ` + `previous value (${this.shape}) must match`);\n    }\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null /* backend */);\n  }\n  dispose() {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  }\n}\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: instance => {\n    return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;\n  }\n});","map":{"version":3,"names":["getGlobal","tensorToString","util","computeStrides","toNestedArray","TensorBuffer","constructor","shape","dtype","values","slice","size","sizeFromShape","n","length","assert","Error","getArrayFromDType","strides","set","value","locs","rank","index","locToIndex","get","i","loc","msg","indexToLoc","Array","Math","floor","toTensor","trackerFn","makeTensor","opHandler","deprecationWarningFn","setTensorTracker","fn","setOpHandler","handler","setDeprecationWarningFn","Tensor","dataId","id","kept","isDisposedInternal","rankType","toString","buffer","vals","data","bufferSync","dataSync","array","arraySync","throwIfDisposed","read","bytes","map","b","decodeString","_a","dataToGPU","options","readToGPU","readSync","Uint8Array","dispose","isDisposed","kerasMask","disposeTensor","print","verbose","clone","cast","variable","trainable","name","makeVariable","Object","defineProperty","Symbol","hasInstance","instance","getGlobalTensorClass","Variable","initialValue","tensorId","assign","newValue","arraysEqual","incRef","disposeVariable","Function"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-core/src/tensor.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Workaround for: https://github.com/bazelbuild/rules_nodejs/issues/1265\n/// <reference types=\"@webgpu/types/dist\" />\n\nimport {getGlobal} from './global_util';\nimport {tensorToString} from './tensor_format';\nimport {DataId, TensorInfo} from './tensor_info';\nimport {ArrayMap, BackendValues, DataType, DataTypeMap, DataValues, NumericDataType, Rank, ShapeMap, SingleValueMap, TypedArray} from './types';\nimport * as util from './util';\nimport {computeStrides, toNestedArray} from './util';\n\nexport interface TensorData<D extends DataType> {\n  dataId?: DataId;\n  values?: DataTypeMap[D];\n}\n\n// This interface mimics KernelBackend (in backend.ts), which would create a\n// circular dependency if imported.\nexport interface Backend {}\n\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class TensorBuffer<R extends Rank, D extends DataType = 'float32'> {\n  size: number;\n  shape: ShapeMap[R];\n  strides: number[];\n  values: DataTypeMap[D];\n\n  constructor(shape: ShapeMap[R], public dtype: D, values?: DataTypeMap[D]) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.size = util.sizeFromShape(shape);\n\n    if (values != null) {\n      const n = values.length;\n      util.assert(\n          n === this.size,\n          () => `Length of values '${n}' does not match the size ` +\n              `inferred by the shape '${this.size}'.`);\n    }\n    if (dtype === 'complex64') {\n      throw new Error(\n          `complex64 dtype TensorBuffers are not supported. Please create ` +\n          `a TensorBuffer for the real and imaginary parts separately and ` +\n          `call tf.complex(real, imag).`);\n    }\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  set(value: SingleValueMap[D], ...locs: number[]): void {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    util.assert(\n        locs.length === this.rank,\n        () => `The number of provided coordinates (${locs.length}) must ` +\n            `match the rank (${this.rank})`);\n\n    const index = this.locToIndex(locs);\n    this.values[index] = value as number;\n  }\n\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  get(...locs: number[]): SingleValueMap[D] {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    let i = 0;\n    for (const loc of locs) {\n      if (loc < 0 || loc >= this.shape[i]) {\n        const msg = `Requested out of range element at ${locs}. ` +\n            `  Buffer shape=${this.shape}`;\n        throw new Error(msg);\n      }\n      i++;\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return this.values[index] as SingleValueMap[D];\n  }\n\n  locToIndex(locs: number[]): number {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return index;\n  }\n\n  indexToLoc(index: number): number[] {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n    const locs: number[] = new Array(this.shape.length);\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  toTensor(): Tensor<R> {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype) as\n        Tensor<R>;\n  }\n}\n\nexport interface DataToGPUWebGLOption {\n  customTexShape?: [number, number];\n}\n\nexport type DataToGPUOptions = DataToGPUWebGLOption;\n\nexport interface GPUData {\n  tensorRef: Tensor;\n  texture?: WebGLTexture;\n  buffer?: GPUBuffer;\n  texShape?: [number, number];\n}\n\nexport interface TensorTracker {\n  makeTensor(\n      values: DataValues, shape: number[], dtype: DataType,\n      backend?: Backend): Tensor;\n  makeVariable(\n      initialValue: Tensor, trainable?: boolean, name?: string,\n      dtype?: DataType): Variable;\n  incRef(a: Tensor, backend: Backend): void;\n  disposeTensor(t: Tensor): void;\n  disposeVariable(v: Variable): void;\n  read(dataId: DataId): Promise<BackendValues>;\n  readSync(dataId: DataId): BackendValues;\n  readToGPU(dataId: DataId, options?: DataToGPUOptions): GPUData;\n}\n\n/**\n * The Tensor class calls into this handler to delegate chaining operations.\n */\nexport interface OpHandler {\n  cast<T extends Tensor>(x: T, dtype: DataType): T;\n  buffer<R extends Rank, D extends DataType>(\n      shape: ShapeMap[R], dtype: D,\n      values?: DataTypeMap[D]): TensorBuffer<R, D>;\n  print<T extends Tensor>(x: T, verbose: boolean): void;\n  clone<T extends Tensor>(x: T): T;\n  // TODO(yassogba) bring reshape back?\n}\n\n// For tracking tensor creation and disposal.\nlet trackerFn: () => TensorTracker = null;\n// Used by chaining methods to call into ops.\nlet opHandler: OpHandler = null;\n// Used to warn about deprecated methods.\nlet deprecationWarningFn: (msg: string) => void = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nexport function setTensorTracker(fn: () => TensorTracker) {\n  trackerFn = fn;\n}\n\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\nexport function setOpHandler(handler: OpHandler) {\n  opHandler = handler;\n}\n\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nexport function setDeprecationWarningFn(fn: (msg: string) => void) {\n  deprecationWarningFn = fn;\n}\n\n// Declare this namespace to make Tensor class augmentation work in google3.\nexport declare namespace Tensor {}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Tensor<R extends Rank = Rank> implements TensorInfo {\n  /** Unique id of this tensor. */\n  readonly id: number;\n  /**\n   * Id of the bucket holding the data for this tensor. Multiple arrays can\n   * point to the same bucket (e.g. when calling array.reshape()).\n   */\n  dataId: DataId;\n  /** The shape of the tensor. */\n  readonly shape: ShapeMap[R];\n  /** Number of elements in the tensor. */\n  readonly size: number;\n  /** The data type for the array. */\n  readonly dtype: DataType;\n  /** The rank type for the array (see `Rank` enum). */\n  readonly rankType: R;\n\n  /** Whether this tensor has been globally kept. */\n  kept = false;\n  /** The id of the scope this tensor is being tracked in. */\n  scopeId: number;\n  /** The keras mask that some keras layers attach to the tensor */\n  kerasMask?: Tensor;\n\n  /**\n   * Number of elements to skip in each dimension when indexing. See\n   * https://docs.scipy.org/doc/numpy/reference/generated/\\\n   * numpy.ndarray.strides.html\n   */\n  readonly strides: number[];\n\n  constructor(shape: ShapeMap[R], dtype: DataType, dataId: DataId, id: number) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher') as R;\n  }\n\n  get rank(): number {\n    return this.shape.length;\n  }\n\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async buffer<D extends DataType = 'float32'>(): Promise<TensorBuffer<R, D>> {\n    const vals = await this.data<D>();\n    return opHandler.buffer(this.shape, this.dtype as D, vals);\n  }\n\n  /**\n   * Returns a `tf.TensorBuffer` that holds the underlying data.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  bufferSync<D extends DataType = 'float32'>(): TensorBuffer<R, D> {\n    return opHandler.buffer(this.shape, this.dtype as D, this.dataSync());\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async array(): Promise<ArrayMap[R]> {\n    const vals = await this.data();\n    return toNestedArray(this.shape, vals, this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  arraySync(): ArrayMap[R] {\n    return toNestedArray(\n               this.shape, this.dataSync(), this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]> {\n    this.throwIfDisposed();\n    const data = trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      const bytes = await data as Uint8Array[];\n      try {\n        return bytes.map(b => util.decodeString(b)) as DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as Promise<DataTypeMap[D]>;\n  }\n\n  /**\n   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n   * and `data()`, this method prevents data from being downloaded to CPU.\n   *\n   * For WebGL backend, the data will be stored on a densely packed texture.\n   * This means that the texture will use the RGBA channels to store value.\n   *\n   * For WebGPU backend, the data will be stored on a buffer. There is no\n   * parameter, so can not use a user-defined size to create the buffer.\n   *\n   * @param options:\n   *     For WebGL,\n   *         - customTexShape: Optional. If set, will use the user defined\n   *     texture shape to create the texture.\n   *\n   * @returns For WebGL backend, a GPUData contains the new texture and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this texture,\n   *        texture: WebGLTexture,\n   *        texShape: [number, number] // [height, width]\n   *     }\n   *\n   *     For WebGPU backend, a GPUData contains the new buffer.\n   *     {\n   *        tensorRef: The tensor that is associated with this buffer,\n   *        buffer: GPUBuffer,\n   *     }\n   *\n   *     Remember to dispose the GPUData after it is used by\n   *     `res.tensorRef.dispose()`.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataToGPU(options?: DataToGPUOptions): GPUData {\n    this.throwIfDisposed();\n    return trackerFn().readToGPU(this.dataId, options);\n  }\n\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D] {\n    this.throwIfDisposed();\n    const data = trackerFn().readSync(this.dataId);\n    if (this.dtype === 'string') {\n      try {\n        return (data as Uint8Array[]).map(b => util.decodeString(b)) as\n            DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as DataTypeMap[D];\n  }\n\n  /** Returns the underlying bytes of the tensor's data. */\n  async bytes(): Promise<Uint8Array[]|Uint8Array> {\n    this.throwIfDisposed();\n    const data = await trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      return data as Uint8Array[];\n    } else {\n      return new Uint8Array((data as TypedArray).buffer);\n    }\n  }\n\n  /**\n   * Disposes `tf.Tensor` from memory.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dispose(): void {\n    if (this.isDisposed) {\n      return;\n    }\n    if (this.kerasMask) {\n      this.kerasMask.dispose();\n    }\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n\n  protected isDisposedInternal = false;\n  get isDisposed(): boolean {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  print(verbose = false): void {\n    return opHandler.print(this, verbose);\n  }\n\n  /**\n   * Returns a copy of the tensor. See `tf.clone` for details.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  clone<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  }\n\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  toString(verbose = false): string {\n    const vals = this.dataSync();\n    return tensorToString(vals, this.shape, this.dtype, verbose);\n  }\n\n  cast<T extends this>(dtype: DataType): T {\n    this.throwIfDisposed();\n    return opHandler.cast(this as T, dtype);\n  }\n  variable(trainable = true, name?: string, dtype?: DataType): Variable<R> {\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype) as\n        Variable<R>;\n  }\n}\n\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: (instance: Tensor) => {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null &&\n        instance.throwIfDisposed != null;\n  }\n});\n\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', () => {\n    return Tensor;\n  });\n}\n\n// Global side effect. Cache global reference to Tensor class\ngetGlobalTensorClass();\n\nexport interface NumericTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: NumericDataType;\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D];\n  data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]>;\n  dataToGPU(options?: DataToGPUOptions): GPUData;\n}\n\nexport interface StringTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: 'string';\n  dataSync<D extends DataType = 'string'>(): DataTypeMap[D];\n  data<D extends DataType = 'string'>(): Promise<DataTypeMap[D]>;\n}\n\n/** @doclink Tensor */\nexport type Scalar = Tensor<Rank.R0>;\n/** @doclink Tensor */\nexport type Tensor1D = Tensor<Rank.R1>;\n/** @doclink Tensor */\nexport type Tensor2D = Tensor<Rank.R2>;\n/** @doclink Tensor */\nexport type Tensor3D = Tensor<Rank.R3>;\n/** @doclink Tensor */\nexport type Tensor4D = Tensor<Rank.R4>;\n/** @doclink Tensor */\nexport type Tensor5D = Tensor<Rank.R5>;\n/** @doclink Tensor */\nexport type Tensor6D = Tensor<Rank.R6>;\n\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Variable<R extends Rank = Rank> extends Tensor<R> {\n  name: string;\n\n  constructor(\n      initialValue: Tensor<R>, public trainable: boolean, name: string,\n      tensorId: number) {\n    super(\n        initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    this.name = name;\n  }\n\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  assign(newValue: Tensor<R>): void {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(\n          `dtype of the new value (${newValue.dtype}) and ` +\n          `previous value (${this.dtype}) must match`);\n    }\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(\n          `shape of the new value (${newValue.shape}) and ` +\n          `previous value (${this.shape}) must match`);\n    }\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null /* backend */);\n  }\n\n  override dispose(): void {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  }\n}\n\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: (instance: Variable) => {\n    return instance instanceof Tensor && instance.assign != null &&\n        instance.assign instanceof Function;\n  }\n});\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA;AACA;AAEA,SAAQA,SAAS,QAAO,eAAe;AACvC,SAAQC,cAAc,QAAO,iBAAiB;AAG9C,OAAO,KAAKC,IAAI,MAAM,QAAQ;AAC9B,SAAQC,cAAc,EAAEC,aAAa,QAAO,QAAQ;AAWpD;;;;;;;;AAQA,OAAM,MAAOC,YAAY;EAMvBC,YAAYC,KAAkB,EAASC,KAAQ,EAAEC,MAAuB;IAAjC,KAAAD,KAAK,GAALA,KAAK;IAC1C,IAAI,CAACD,KAAK,GAAGA,KAAK,CAACG,KAAK,EAAiB;IACzC,IAAI,CAACC,IAAI,GAAGT,IAAI,CAACU,aAAa,CAACL,KAAK,CAAC;IAErC,IAAIE,MAAM,IAAI,IAAI,EAAE;MAClB,MAAMI,CAAC,GAAGJ,MAAM,CAACK,MAAM;MACvBZ,IAAI,CAACa,MAAM,CACPF,CAAC,KAAK,IAAI,CAACF,IAAI,EACf,MAAM,qBAAqBE,CAAC,4BAA4B,GACpD,0BAA0B,IAAI,CAACF,IAAI,IAAI,CAAC;;IAElD,IAAIH,KAAK,KAAK,WAAW,EAAE;MACzB,MAAM,IAAIQ,KAAK,CACX,iEAAiE,GACjE,iEAAiE,GACjE,8BAA8B,CAAC;;IAErC,IAAI,CAACP,MAAM,GAAGA,MAAM,IAAIP,IAAI,CAACe,iBAAiB,CAACT,KAAK,EAAE,IAAI,CAACG,IAAI,CAAC;IAChE,IAAI,CAACO,OAAO,GAAGf,cAAc,CAACI,KAAK,CAAC;EACtC;EAEA;;;;;;;;EAQAY,GAAGA,CAACC,KAAwB,EAAE,GAAGC,IAAc;IAC7C,IAAIA,IAAI,CAACP,MAAM,KAAK,CAAC,EAAE;MACrBO,IAAI,GAAG,CAAC,CAAC,CAAC;;IAEZnB,IAAI,CAACa,MAAM,CACPM,IAAI,CAACP,MAAM,KAAK,IAAI,CAACQ,IAAI,EACzB,MAAM,uCAAuCD,IAAI,CAACP,MAAM,SAAS,GAC7D,mBAAmB,IAAI,CAACQ,IAAI,GAAG,CAAC;IAExC,MAAMC,KAAK,GAAG,IAAI,CAACC,UAAU,CAACH,IAAI,CAAC;IACnC,IAAI,CAACZ,MAAM,CAACc,KAAK,CAAC,GAAGH,KAAe;EACtC;EAEA;;;;;;;EAOAK,GAAGA,CAAC,GAAGJ,IAAc;IACnB,IAAIA,IAAI,CAACP,MAAM,KAAK,CAAC,EAAE;MACrBO,IAAI,GAAG,CAAC,CAAC,CAAC;;IAEZ,IAAIK,CAAC,GAAG,CAAC;IACT,KAAK,MAAMC,GAAG,IAAIN,IAAI,EAAE;MACtB,IAAIM,GAAG,GAAG,CAAC,IAAIA,GAAG,IAAI,IAAI,CAACpB,KAAK,CAACmB,CAAC,CAAC,EAAE;QACnC,MAAME,GAAG,GAAG,qCAAqCP,IAAI,IAAI,GACrD,kBAAkB,IAAI,CAACd,KAAK,EAAE;QAClC,MAAM,IAAIS,KAAK,CAACY,GAAG,CAAC;;MAEtBF,CAAC,EAAE;;IAEL,IAAIH,KAAK,GAAGF,IAAI,CAACA,IAAI,CAACP,MAAM,GAAG,CAAC,CAAC;IACjC,KAAK,IAAIY,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,IAAI,CAACP,MAAM,GAAG,CAAC,EAAE,EAAEY,CAAC,EAAE;MACxCH,KAAK,IAAI,IAAI,CAACL,OAAO,CAACQ,CAAC,CAAC,GAAGL,IAAI,CAACK,CAAC,CAAC;;IAEpC,OAAO,IAAI,CAACjB,MAAM,CAACc,KAAK,CAAsB;EAChD;EAEAC,UAAUA,CAACH,IAAc;IACvB,IAAI,IAAI,CAACC,IAAI,KAAK,CAAC,EAAE;MACnB,OAAO,CAAC;KACT,MAAM,IAAI,IAAI,CAACA,IAAI,KAAK,CAAC,EAAE;MAC1B,OAAOD,IAAI,CAAC,CAAC,CAAC;;IAEhB,IAAIE,KAAK,GAAGF,IAAI,CAACA,IAAI,CAACP,MAAM,GAAG,CAAC,CAAC;IACjC,KAAK,IAAIY,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,IAAI,CAACP,MAAM,GAAG,CAAC,EAAE,EAAEY,CAAC,EAAE;MACxCH,KAAK,IAAI,IAAI,CAACL,OAAO,CAACQ,CAAC,CAAC,GAAGL,IAAI,CAACK,CAAC,CAAC;;IAEpC,OAAOH,KAAK;EACd;EAEAM,UAAUA,CAACN,KAAa;IACtB,IAAI,IAAI,CAACD,IAAI,KAAK,CAAC,EAAE;MACnB,OAAO,EAAE;KACV,MAAM,IAAI,IAAI,CAACA,IAAI,KAAK,CAAC,EAAE;MAC1B,OAAO,CAACC,KAAK,CAAC;;IAEhB,MAAMF,IAAI,GAAa,IAAIS,KAAK,CAAC,IAAI,CAACvB,KAAK,CAACO,MAAM,CAAC;IACnD,KAAK,IAAIY,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,IAAI,CAACP,MAAM,GAAG,CAAC,EAAE,EAAEY,CAAC,EAAE;MACxCL,IAAI,CAACK,CAAC,CAAC,GAAGK,IAAI,CAACC,KAAK,CAACT,KAAK,GAAG,IAAI,CAACL,OAAO,CAACQ,CAAC,CAAC,CAAC;MAC7CH,KAAK,IAAIF,IAAI,CAACK,CAAC,CAAC,GAAG,IAAI,CAACR,OAAO,CAACQ,CAAC,CAAC;;IAEpCL,IAAI,CAACA,IAAI,CAACP,MAAM,GAAG,CAAC,CAAC,GAAGS,KAAK;IAC7B,OAAOF,IAAI;EACb;EAEA,IAAIC,IAAIA,CAAA;IACN,OAAO,IAAI,CAACf,KAAK,CAACO,MAAM;EAC1B;EAEA;;;;;EAKAmB,QAAQA,CAAA;IACN,OAAOC,SAAS,EAAE,CAACC,UAAU,CAAC,IAAI,CAAC1B,MAAM,EAAE,IAAI,CAACF,KAAK,EAAE,IAAI,CAACC,KAAK,CACpD;EACf;;AA4CF;AACA,IAAI0B,SAAS,GAAwB,IAAI;AACzC;AACA,IAAIE,SAAS,GAAc,IAAI;AAC/B;AACA,IAAIC,oBAAoB,GAA0B,IAAI;AACtD;AACA;AACA;AACA,CAACA,oBAAoB,CAAC;AAEtB;;;;;AAKA,OAAM,SAAUC,gBAAgBA,CAACC,EAAuB;EACtDL,SAAS,GAAGK,EAAE;AAChB;AAEA;;;;;AAKA,OAAM,SAAUC,YAAYA,CAACC,OAAkB;EAC7CL,SAAS,GAAGK,OAAO;AACrB;AAEA;;;;AAIA,OAAM,SAAUC,uBAAuBA,CAACH,EAAyB;EAC/DF,oBAAoB,GAAGE,EAAE;AAC3B;AAIA;;;;;;;;;;;;;;AAcA,OAAM,MAAOI,MAAM;EA+BjBrC,YAAYC,KAAkB,EAAEC,KAAe,EAAEoC,MAAc,EAAEC,EAAU;IAd3E;IACA,KAAAC,IAAI,GAAG,KAAK;IAmLF,KAAAC,kBAAkB,GAAG,KAAK;IArKlC,IAAI,CAACxC,KAAK,GAAGA,KAAK,CAACG,KAAK,EAAiB;IACzC,IAAI,CAACF,KAAK,GAAGA,KAAK,IAAI,SAAS;IAC/B,IAAI,CAACG,IAAI,GAAGT,IAAI,CAACU,aAAa,CAACL,KAAK,CAAC;IACrC,IAAI,CAACW,OAAO,GAAGf,cAAc,CAACI,KAAK,CAAC;IACpC,IAAI,CAACqC,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACC,EAAE,GAAGA,EAAE;IACZ,IAAI,CAACG,QAAQ,GAAI,IAAI,CAAC1B,IAAI,GAAG,CAAC,GAAG,IAAI,CAACA,IAAI,CAAC2B,QAAQ,EAAE,GAAG,QAAc;EACxE;EAEA,IAAI3B,IAAIA,CAAA;IACN,OAAO,IAAI,CAACf,KAAK,CAACO,MAAM;EAC1B;EAEA;;;;;EAKA,MAAMoC,MAAMA,CAAA;IACV,MAAMC,IAAI,GAAG,MAAM,IAAI,CAACC,IAAI,EAAK;IACjC,OAAOhB,SAAS,CAACc,MAAM,CAAC,IAAI,CAAC3C,KAAK,EAAE,IAAI,CAACC,KAAU,EAAE2C,IAAI,CAAC;EAC5D;EAEA;;;;EAIAE,UAAUA,CAAA;IACR,OAAOjB,SAAS,CAACc,MAAM,CAAC,IAAI,CAAC3C,KAAK,EAAE,IAAI,CAACC,KAAU,EAAE,IAAI,CAAC8C,QAAQ,EAAE,CAAC;EACvE;EAEA;;;;;;EAMA,MAAMC,KAAKA,CAAA;IACT,MAAMJ,IAAI,GAAG,MAAM,IAAI,CAACC,IAAI,EAAE;IAC9B,OAAOhD,aAAa,CAAC,IAAI,CAACG,KAAK,EAAE4C,IAAI,EAAE,IAAI,CAAC3C,KAAK,KAAK,WAAW,CAClD;EACjB;EAEA;;;;;;EAMAgD,SAASA,CAAA;IACP,OAAOpD,aAAa,CACT,IAAI,CAACG,KAAK,EAAE,IAAI,CAAC+C,QAAQ,EAAE,EAAE,IAAI,CAAC9C,KAAK,KAAK,WAAW,CACnD;EACjB;EAEA;;;;;;EAMA,MAAM4C,IAAIA,CAAA;IACR,IAAI,CAACK,eAAe,EAAE;IACtB,MAAML,IAAI,GAAGlB,SAAS,EAAE,CAACwB,IAAI,CAAC,IAAI,CAACd,MAAM,CAAC;IAC1C,IAAI,IAAI,CAACpC,KAAK,KAAK,QAAQ,EAAE;MAC3B,MAAMmD,KAAK,GAAG,MAAMP,IAAoB;MACxC,IAAI;QACF,OAAOO,KAAK,CAACC,GAAG,CAACC,CAAC,IAAI3D,IAAI,CAAC4D,YAAY,CAACD,CAAC,CAAC,CAAmB;OAC9D,CAAC,OAAAE,EAAA,EAAM;QACN,MAAM,IAAI/C,KAAK,CACX,gDAAgD,GAChD,iDAAiD,CAAC;;;IAG1D,OAAOoC,IAA+B;EACxC;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkCAY,SAASA,CAACC,OAA0B;IAClC,IAAI,CAACR,eAAe,EAAE;IACtB,OAAOvB,SAAS,EAAE,CAACgC,SAAS,CAAC,IAAI,CAACtB,MAAM,EAAEqB,OAAO,CAAC;EACpD;EAEA;;;;;;EAMAX,QAAQA,CAAA;IACN,IAAI,CAACG,eAAe,EAAE;IACtB,MAAML,IAAI,GAAGlB,SAAS,EAAE,CAACiC,QAAQ,CAAC,IAAI,CAACvB,MAAM,CAAC;IAC9C,IAAI,IAAI,CAACpC,KAAK,KAAK,QAAQ,EAAE;MAC3B,IAAI;QACF,OAAQ4C,IAAqB,CAACQ,GAAG,CAACC,CAAC,IAAI3D,IAAI,CAAC4D,YAAY,CAACD,CAAC,CAAC,CACzC;OACnB,CAAC,OAAAE,EAAA,EAAM;QACN,MAAM,IAAI/C,KAAK,CACX,gDAAgD,GAChD,iDAAiD,CAAC;;;IAG1D,OAAOoC,IAAsB;EAC/B;EAEA;EACA,MAAMO,KAAKA,CAAA;IACT,IAAI,CAACF,eAAe,EAAE;IACtB,MAAML,IAAI,GAAG,MAAMlB,SAAS,EAAE,CAACwB,IAAI,CAAC,IAAI,CAACd,MAAM,CAAC;IAChD,IAAI,IAAI,CAACpC,KAAK,KAAK,QAAQ,EAAE;MAC3B,OAAO4C,IAAoB;KAC5B,MAAM;MACL,OAAO,IAAIgB,UAAU,CAAEhB,IAAmB,CAACF,MAAM,CAAC;;EAEtD;EAEA;;;;;EAKAmB,OAAOA,CAAA;IACL,IAAI,IAAI,CAACC,UAAU,EAAE;MACnB;;IAEF,IAAI,IAAI,CAACC,SAAS,EAAE;MAClB,IAAI,CAACA,SAAS,CAACF,OAAO,EAAE;;IAE1BnC,SAAS,EAAE,CAACsC,aAAa,CAAC,IAAI,CAAC;IAC/B,IAAI,CAACzB,kBAAkB,GAAG,IAAI;EAChC;EAGA,IAAIuB,UAAUA,CAAA;IACZ,OAAO,IAAI,CAACvB,kBAAkB;EAChC;EAEAU,eAAeA,CAAA;IACb,IAAI,IAAI,CAACa,UAAU,EAAE;MACnB,MAAM,IAAItD,KAAK,CAAC,qBAAqB,CAAC;;EAE1C;EAEA;;;;;;;;EAQAyD,KAAKA,CAACC,OAAO,GAAG,KAAK;IACnB,OAAOtC,SAAS,CAACqC,KAAK,CAAC,IAAI,EAAEC,OAAO,CAAC;EACvC;EAEA;;;;EAIAC,KAAKA,CAAA;IACH,IAAI,CAAClB,eAAe,EAAE;IACtB,OAAOrB,SAAS,CAACuC,KAAK,CAAC,IAAI,CAAC;EAC9B;EAEA;;;;;EAKA1B,QAAQA,CAACyB,OAAO,GAAG,KAAK;IACtB,MAAMvB,IAAI,GAAG,IAAI,CAACG,QAAQ,EAAE;IAC5B,OAAOrD,cAAc,CAACkD,IAAI,EAAE,IAAI,CAAC5C,KAAK,EAAE,IAAI,CAACC,KAAK,EAAEkE,OAAO,CAAC;EAC9D;EAEAE,IAAIA,CAAiBpE,KAAe;IAClC,IAAI,CAACiD,eAAe,EAAE;IACtB,OAAOrB,SAAS,CAACwC,IAAI,CAAC,IAAS,EAAEpE,KAAK,CAAC;EACzC;EACAqE,QAAQA,CAACC,SAAS,GAAG,IAAI,EAAEC,IAAa,EAAEvE,KAAgB;IACxD,IAAI,CAACiD,eAAe,EAAE;IACtB,OAAOvB,SAAS,EAAE,CAAC8C,YAAY,CAAC,IAAI,EAAEF,SAAS,EAAEC,IAAI,EAAEvE,KAAK,CAC7C;EACjB;;AAGFyE,MAAM,CAACC,cAAc,CAACvC,MAAM,EAAEwC,MAAM,CAACC,WAAW,EAAE;EAChDhE,KAAK,EAAGiE,QAAgB,IAAI;IAC1B;IACA;IACA;IACA;IACA;IACA,OAAO,CAAC,CAACA,QAAQ,IAAIA,QAAQ,CAACjC,IAAI,IAAI,IAAI,IAAIiC,QAAQ,CAAC/B,QAAQ,IAAI,IAAI,IACnE+B,QAAQ,CAAC5B,eAAe,IAAI,IAAI;EACtC;CACD,CAAC;AAEF,OAAM,SAAU6B,oBAAoBA,CAAA;EAClC;EACA;EACA;EACA,OAAOtF,SAAS,CAAC,QAAQ,EAAE,MAAK;IAC9B,OAAO2C,MAAM;EACf,CAAC,CAAC;AACJ;AAEA;AACA2C,oBAAoB,EAAE;AA8BtB;;;;;AAKA,OAAM,MAAOC,QAAgC,SAAQ5C,MAAS;EAG5DrC,YACIkF,YAAuB,EAASV,SAAkB,EAAEC,IAAY,EAChEU,QAAgB;IAClB,KAAK,CACDD,YAAY,CAACjF,KAAK,EAAEiF,YAAY,CAAChF,KAAK,EAAEgF,YAAY,CAAC5C,MAAM,EAAE6C,QAAQ,CAAC;IAHxC,KAAAX,SAAS,GAATA,SAAS;IAI3C,IAAI,CAACC,IAAI,GAAGA,IAAI;EAClB;EAEA;;;;;;;;EAQAW,MAAMA,CAACC,QAAmB;IACxB,IAAIA,QAAQ,CAACnF,KAAK,KAAK,IAAI,CAACA,KAAK,EAAE;MACjC,MAAM,IAAIQ,KAAK,CACX,2BAA2B2E,QAAQ,CAACnF,KAAK,QAAQ,GACjD,mBAAmB,IAAI,CAACA,KAAK,cAAc,CAAC;;IAElD,IAAI,CAACN,IAAI,CAAC0F,WAAW,CAACD,QAAQ,CAACpF,KAAK,EAAE,IAAI,CAACA,KAAK,CAAC,EAAE;MACjD,MAAM,IAAIS,KAAK,CACX,2BAA2B2E,QAAQ,CAACpF,KAAK,QAAQ,GACjD,mBAAmB,IAAI,CAACA,KAAK,cAAc,CAAC;;IAElD2B,SAAS,EAAE,CAACsC,aAAa,CAAC,IAAI,CAAC;IAC/B,IAAI,CAAC5B,MAAM,GAAG+C,QAAQ,CAAC/C,MAAM;IAC7BV,SAAS,EAAE,CAAC2D,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,aAAa,CAAC;EAC9C;EAESxB,OAAOA,CAAA;IACdnC,SAAS,EAAE,CAAC4D,eAAe,CAAC,IAAI,CAAC;IACjC,IAAI,CAAC/C,kBAAkB,GAAG,IAAI;EAChC;;AAGFkC,MAAM,CAACC,cAAc,CAACK,QAAQ,EAAEJ,MAAM,CAACC,WAAW,EAAE;EAClDhE,KAAK,EAAGiE,QAAkB,IAAI;IAC5B,OAAOA,QAAQ,YAAY1C,MAAM,IAAI0C,QAAQ,CAACK,MAAM,IAAI,IAAI,IACxDL,QAAQ,CAACK,MAAM,YAAYK,QAAQ;EACzC;CACD,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}