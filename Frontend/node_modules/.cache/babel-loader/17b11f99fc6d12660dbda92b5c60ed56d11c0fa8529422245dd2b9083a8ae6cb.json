{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { FusedConv2D } from '@tensorflow/tfjs-core';\nimport { applyActivation } from '../utils/fused_utils';\nimport { add } from './Add';\nimport { conv2D } from './Conv2D';\nimport { reshape } from './Reshape';\nexport function fusedConv2D(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x,\n    filter,\n    bias,\n    preluActivationWeights\n  } = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n  let result = conv2D({\n    inputs: {\n      x,\n      filter\n    },\n    backend,\n    attrs: {\n      strides,\n      pad,\n      dataFormat,\n      dilations,\n      dimRoundingMode\n    }\n  });\n  if (bias) {\n    const resultOld = result;\n    // For NCHW format, if bias is a 1-D tensor, it is supposed to be aligned\n    // to the channel of the conv2d's result; if the bias is a scalar, the\n    // bias_add is computed as if the bias was broadcasted to the shape of the\n    // conv2d's result.\n    if (dataFormat === 'NCHW' && bias.shape.length === 1 && bias.shape[0] !== 1) {\n      const reshapedBias = reshape({\n        inputs: {\n          x: bias\n        },\n        backend,\n        attrs: {\n          shape: [bias.shape[0], 1, 1]\n        }\n      });\n      result = add({\n        inputs: {\n          a: result,\n          b: reshapedBias\n        },\n        backend\n      });\n      backend.disposeIntermediateTensorInfo(reshapedBias);\n    } else {\n      // This condition handles NHWC and NCHW (scalar case). The only other case\n      // for NCHW (1D case) is handled above.\n      result = add({\n        inputs: {\n          a: result,\n          b: bias\n        },\n        backend\n      });\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n  if (activation) {\n    const resultOld = result;\n    // For NCHW format, if PReLu activation weights is a 1-D tensor, it is\n    // supposed to be aligned with the channel of the conv2d's result. For other\n    // cases, whether NCHW or NHWC data format, the conv2d result is\n    // already aligned with the activation weights.\n    if (dataFormat === 'NCHW' && activation === 'prelu' && preluActivationWeights.shape.length === 1 && preluActivationWeights.shape[0] !== 1) {\n      const reshapedAlpha = reshape({\n        inputs: {\n          x: preluActivationWeights\n        },\n        backend,\n        attrs: {\n          shape: [preluActivationWeights.shape[0], 1, 1]\n        }\n      });\n      result = applyActivation(backend, result, activation, reshapedAlpha, leakyreluAlpha);\n      backend.disposeIntermediateTensorInfo(reshapedAlpha);\n    } else {\n      result = applyActivation(backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n  return result;\n}\nexport const fusedConv2DConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedConv2D\n};","map":{"version":3,"names":["FusedConv2D","applyActivation","add","conv2D","reshape","fusedConv2D","args","inputs","backend","attrs","x","filter","bias","preluActivationWeights","strides","pad","dataFormat","dilations","dimRoundingMode","activation","leakyreluAlpha","result","resultOld","shape","length","reshapedBias","a","b","disposeIntermediateTensorInfo","reshapedAlpha","fusedConv2DConfig","kernelName","backendName","kernelFunc"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-backend-cpu/src/kernels/FusedConv2D.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {conv2D} from './Conv2D';\nimport {reshape} from './Reshape';\n\nexport function fusedConv2D(args: {\n  inputs: FusedConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  let result = conv2D({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const resultOld = result;\n    // For NCHW format, if bias is a 1-D tensor, it is supposed to be aligned\n    // to the channel of the conv2d's result; if the bias is a scalar, the\n    // bias_add is computed as if the bias was broadcasted to the shape of the\n    // conv2d's result.\n    if (dataFormat === 'NCHW' && bias.shape.length === 1 &&\n        bias.shape[0] !== 1) {\n      const reshapedBias = reshape(\n          {inputs: {x: bias}, backend, attrs: {shape: [bias.shape[0], 1, 1]}});\n      result =\n          add({inputs: {a: result, b: reshapedBias}, backend}) as TensorInfo;\n      backend.disposeIntermediateTensorInfo(reshapedBias);\n    } else {\n      // This condition handles NHWC and NCHW (scalar case). The only other case\n      // for NCHW (1D case) is handled above.\n      result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  if (activation) {\n    const resultOld = result;\n    // For NCHW format, if PReLu activation weights is a 1-D tensor, it is\n    // supposed to be aligned with the channel of the conv2d's result. For other\n    // cases, whether NCHW or NHWC data format, the conv2d result is\n    // already aligned with the activation weights.\n    if (dataFormat === 'NCHW' && activation === 'prelu' &&\n        preluActivationWeights.shape.length === 1 &&\n        preluActivationWeights.shape[0] !== 1) {\n      const reshapedAlpha = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: [preluActivationWeights.shape[0], 1, 1]}\n      });\n      result = applyActivation(\n          backend, result, activation, reshapedAlpha, leakyreluAlpha);\n      backend.disposeIntermediateTensorInfo(reshapedAlpha);\n    } else {\n      result = applyActivation(\n          backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  return result;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedConv2D as unknown as KernelFunc\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,WAAW,QAAkF,uBAAuB;AAG5H,SAAQC,eAAe,QAAO,sBAAsB;AACpD,SAAQC,GAAG,QAAO,OAAO;AACzB,SAAQC,MAAM,QAAO,UAAU;AAC/B,SAAQC,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAUC,WAAWA,CAACC,IAI3B;EACC,MAAM;IAACC,MAAM;IAAEC,OAAO;IAAEC;EAAK,CAAC,GAAGH,IAAI;EACrC,MAAM;IAACI,CAAC;IAAEC,MAAM;IAAEC,IAAI;IAAEC;EAAsB,CAAC,GAAGN,MAAM;EACxD,MAAM;IACJO,OAAO;IACPC,GAAG;IACHC,UAAU;IACVC,SAAS;IACTC,eAAe;IACfC,UAAU;IACVC;EAAc,CACf,GAAGX,KAAK;EAET,IAAIY,MAAM,GAAGlB,MAAM,CAAC;IAClBI,MAAM,EAAE;MAACG,CAAC;MAAEC;IAAM,CAAC;IACnBH,OAAO;IACPC,KAAK,EAAE;MAACK,OAAO;MAAEC,GAAG;MAAEC,UAAU;MAAEC,SAAS;MAAEC;IAAe;GAC7D,CAAC;EAEF,IAAIN,IAAI,EAAE;IACR,MAAMU,SAAS,GAAGD,MAAM;IACxB;IACA;IACA;IACA;IACA,IAAIL,UAAU,KAAK,MAAM,IAAIJ,IAAI,CAACW,KAAK,CAACC,MAAM,KAAK,CAAC,IAChDZ,IAAI,CAACW,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;MACvB,MAAME,YAAY,GAAGrB,OAAO,CACxB;QAACG,MAAM,EAAE;UAACG,CAAC,EAAEE;QAAI,CAAC;QAAEJ,OAAO;QAAEC,KAAK,EAAE;UAACc,KAAK,EAAE,CAACX,IAAI,CAACW,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC;QAAC;MAAC,CAAC,CAAC;MACxEF,MAAM,GACFnB,GAAG,CAAC;QAACK,MAAM,EAAE;UAACmB,CAAC,EAAEL,MAAM;UAAEM,CAAC,EAAEF;QAAY,CAAC;QAAEjB;MAAO,CAAC,CAAe;MACtEA,OAAO,CAACoB,6BAA6B,CAACH,YAAY,CAAC;KACpD,MAAM;MACL;MACA;MACAJ,MAAM,GAAGnB,GAAG,CAAC;QAACK,MAAM,EAAE;UAACmB,CAAC,EAAEL,MAAM;UAAEM,CAAC,EAAEf;QAAI,CAAC;QAAEJ;MAAO,CAAC,CAAe;;IAErEA,OAAO,CAACoB,6BAA6B,CAACN,SAAS,CAAC;;EAGlD,IAAIH,UAAU,EAAE;IACd,MAAMG,SAAS,GAAGD,MAAM;IACxB;IACA;IACA;IACA;IACA,IAAIL,UAAU,KAAK,MAAM,IAAIG,UAAU,KAAK,OAAO,IAC/CN,sBAAsB,CAACU,KAAK,CAACC,MAAM,KAAK,CAAC,IACzCX,sBAAsB,CAACU,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;MACzC,MAAMM,aAAa,GAAGzB,OAAO,CAAC;QAC5BG,MAAM,EAAE;UAACG,CAAC,EAAEG;QAAsB,CAAC;QACnCL,OAAO;QACPC,KAAK,EAAE;UAACc,KAAK,EAAE,CAACV,sBAAsB,CAACU,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC;QAAC;OACvD,CAAC;MACFF,MAAM,GAAGpB,eAAe,CACpBO,OAAO,EAAEa,MAAM,EAAEF,UAAU,EAAEU,aAAa,EAAET,cAAc,CAAC;MAC/DZ,OAAO,CAACoB,6BAA6B,CAACC,aAAa,CAAC;KACrD,MAAM;MACLR,MAAM,GAAGpB,eAAe,CACpBO,OAAO,EAAEa,MAAM,EAAEF,UAAU,EAAEN,sBAAsB,EAAEO,cAAc,CAAC;;IAE1EZ,OAAO,CAACoB,6BAA6B,CAACN,SAAS,CAAC;;EAGlD,OAAOD,MAAM;AACf;AAEA,OAAO,MAAMS,iBAAiB,GAAiB;EAC7CC,UAAU,EAAE/B,WAAW;EACvBgC,WAAW,EAAE,KAAK;EAClBC,UAAU,EAAE5B;CACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}