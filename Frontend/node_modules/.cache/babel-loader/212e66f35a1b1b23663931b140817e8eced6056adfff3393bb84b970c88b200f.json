{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Pow } from '../kernel_names';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport { cast } from '../ops/cast';\nimport { greater } from '../ops/greater';\nimport { log } from '../ops/log';\nimport { mul } from '../ops/mul';\nimport { pow } from '../ops/pow';\nimport { reshape } from '../ops/reshape';\nimport { scalar } from '../ops/scalar';\nimport { sub } from '../ops/sub';\nimport { sum } from '../ops/sum';\nimport { where } from '../ops/where';\nimport { zerosLike } from '../ops/zeros_like';\nexport const powGradConfig = {\n  kernelName: Pow,\n  inputsToSave: ['a', 'b'],\n  outputsToSave: [true],\n  gradFunc: (dy, saved) => {\n    const [a, b, y] = saved;\n    const base = a;\n    const exp = b;\n    const outShape = broadcast_util.assertAndGetBroadcastShape(base.shape, exp.shape);\n    const derBase = () => {\n      const expFloat = cast(exp, 'float32');\n      let res = mul(dy, mul(expFloat, pow(base, sub(expFloat, scalar(1)))));\n      const reduceAxes = broadcast_util.getReductionAxes(base.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, base.shape);\n    };\n    const derExp = () => {\n      const condition = greater(base, 0);\n      const logBase = where(condition, log(base), zerosLike(base));\n      let res = mul(dy, mul(y, logBase));\n      const reduceAxes = broadcast_util.getReductionAxes(exp.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, exp.shape);\n    };\n    return {\n      a: derBase,\n      b: derExp\n    };\n  }\n};","map":{"version":3,"names":["Pow","broadcast_util","cast","greater","log","mul","pow","reshape","scalar","sub","sum","where","zerosLike","powGradConfig","kernelName","inputsToSave","outputsToSave","gradFunc","dy","saved","a","b","y","base","exp","outShape","assertAndGetBroadcastShape","shape","derBase","expFloat","res","reduceAxes","getReductionAxes","length","derExp","condition","logBase"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-core/src/gradients/Pow_grad.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Pow} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport {cast} from '../ops/cast';\nimport {greater} from '../ops/greater';\nimport {log} from '../ops/log';\nimport {mul} from '../ops/mul';\nimport {pow} from '../ops/pow';\nimport {reshape} from '../ops/reshape';\nimport {scalar} from '../ops/scalar';\nimport {sub} from '../ops/sub';\nimport {sum} from '../ops/sum';\nimport {where} from '../ops/where';\nimport {zerosLike} from '../ops/zeros_like';\nimport {Tensor} from '../tensor';\n\nexport const powGradConfig: GradConfig = {\n  kernelName: Pow,\n  inputsToSave: ['a', 'b'],\n  outputsToSave: [true],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [a, b, y] = saved;\n    const base = a;\n    const exp = b;\n    const outShape =\n        broadcast_util.assertAndGetBroadcastShape(base.shape, exp.shape);\n\n    const derBase = () => {\n      const expFloat = cast(exp, 'float32');\n      let res = mul(dy, mul(expFloat, pow(base, sub(expFloat, scalar(1)))));\n      const reduceAxes = broadcast_util.getReductionAxes(base.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, base.shape);\n    };\n    const derExp = () => {\n      const condition = greater(base, 0);\n      const logBase = where(condition, log(base), zerosLike(base));\n      let res = mul(dy, mul(y, logBase));\n      const reduceAxes = broadcast_util.getReductionAxes(exp.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, exp.shape);\n    };\n    return {a: derBase, b: derExp};\n  }\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAgBA,SAAQA,GAAG,QAAO,iBAAiB;AAEnC,OAAO,KAAKC,cAAc,MAAM,uBAAuB;AACvD,SAAQC,IAAI,QAAO,aAAa;AAChC,SAAQC,OAAO,QAAO,gBAAgB;AACtC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,OAAO,QAAO,gBAAgB;AACtC,SAAQC,MAAM,QAAO,eAAe;AACpC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,KAAK,QAAO,cAAc;AAClC,SAAQC,SAAS,QAAO,mBAAmB;AAG3C,OAAO,MAAMC,aAAa,GAAe;EACvCC,UAAU,EAAEd,GAAG;EACfe,YAAY,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;EACxBC,aAAa,EAAE,CAAC,IAAI,CAAC;EACrBC,QAAQ,EAAEA,CAACC,EAAU,EAAEC,KAAe,KAAI;IACxC,MAAM,CAACC,CAAC,EAAEC,CAAC,EAAEC,CAAC,CAAC,GAAGH,KAAK;IACvB,MAAMI,IAAI,GAAGH,CAAC;IACd,MAAMI,GAAG,GAAGH,CAAC;IACb,MAAMI,QAAQ,GACVxB,cAAc,CAACyB,0BAA0B,CAACH,IAAI,CAACI,KAAK,EAAEH,GAAG,CAACG,KAAK,CAAC;IAEpE,MAAMC,OAAO,GAAGA,CAAA,KAAK;MACnB,MAAMC,QAAQ,GAAG3B,IAAI,CAACsB,GAAG,EAAE,SAAS,CAAC;MACrC,IAAIM,GAAG,GAAGzB,GAAG,CAACa,EAAE,EAAEb,GAAG,CAACwB,QAAQ,EAAEvB,GAAG,CAACiB,IAAI,EAAEd,GAAG,CAACoB,QAAQ,EAAErB,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;MACrE,MAAMuB,UAAU,GAAG9B,cAAc,CAAC+B,gBAAgB,CAACT,IAAI,CAACI,KAAK,EAAEF,QAAQ,CAAC;MACxE,IAAIM,UAAU,CAACE,MAAM,GAAG,CAAC,EAAE;QACzBH,GAAG,GAAGpB,GAAG,CAACoB,GAAG,EAAEC,UAAU,CAAC;;MAE5B,OAAOxB,OAAO,CAACuB,GAAG,EAAEP,IAAI,CAACI,KAAK,CAAC;IACjC,CAAC;IACD,MAAMO,MAAM,GAAGA,CAAA,KAAK;MAClB,MAAMC,SAAS,GAAGhC,OAAO,CAACoB,IAAI,EAAE,CAAC,CAAC;MAClC,MAAMa,OAAO,GAAGzB,KAAK,CAACwB,SAAS,EAAE/B,GAAG,CAACmB,IAAI,CAAC,EAAEX,SAAS,CAACW,IAAI,CAAC,CAAC;MAC5D,IAAIO,GAAG,GAAGzB,GAAG,CAACa,EAAE,EAAEb,GAAG,CAACiB,CAAC,EAAEc,OAAO,CAAC,CAAC;MAClC,MAAML,UAAU,GAAG9B,cAAc,CAAC+B,gBAAgB,CAACR,GAAG,CAACG,KAAK,EAAEF,QAAQ,CAAC;MACvE,IAAIM,UAAU,CAACE,MAAM,GAAG,CAAC,EAAE;QACzBH,GAAG,GAAGpB,GAAG,CAACoB,GAAG,EAAEC,UAAU,CAAC;;MAE5B,OAAOxB,OAAO,CAACuB,GAAG,EAAEN,GAAG,CAACG,KAAK,CAAC;IAChC,CAAC;IACD,OAAO;MAACP,CAAC,EAAEQ,OAAO;MAAEP,CAAC,EAAEa;IAAM,CAAC;EAChC;CACD","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}