{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(array => sliceArraysByIndices(array, indices));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : tfc.cast(indices, 'int32'));\n    }\n  });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(size, batchSize) {\n  const output = [];\n  let batchStart = 0;\n  let batchEnd = null;\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n  return output;\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n  const outs = [];\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  }\n  // Make Tensors at least 2D.\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n  return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n  const oldTensorIds = [];\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n  const tensorsToDispose = [];\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":{"version":3,"names":["tfc","Tensor","expandDims","gather","sliceAlongFirstAxis","checkBatchSize","batchSize","util","assert","Number","isInteger","sliceArrays","arrays","start","stop","Array","isArray","map","array","sliceArraysByIndices","indices","tidy","dtype","cast","makeBatches","size","output","batchStart","batchEnd","push","ensureTensorsRank2OrHigher","tensors","outs","i","length","tensor","rank","Error","disposeNewTensors","refTensors","oldTensorIds","id","forEach","t","name","oldTensor","tensorsToDispose","indexOf","isDisposed","dispose"],"sources":["/Users/jonchen/Documents/HackPSU/tfjs-layers/src/engine/training_tensors.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {Tensor, Tensor1D} from '@tensorflow/tfjs-core';\nimport {expandDims, gather, sliceAlongFirstAxis} from '../backend/tfjs_backend';\nimport {BaseCallback, CustomCallbackArgs, ModelLoggingVerbosity, YieldEveryOptions} from '../base_callbacks';\nimport {ClassWeight, ClassWeightMap} from './training_utils';\n\n/**\n * Interface configuration model training based on data as `tf.Tensor`s.\n */\nexport interface ModelFitArgs {\n  /**\n   * Number of samples per gradient update. If unspecified, it\n   * will default to 32.\n   */\n  batchSize?: number;\n\n  /**\n   * Integer number of times to iterate over the training data arrays.\n   */\n  epochs?: number;\n\n  /**\n   * Verbosity level.\n   *\n   * Expected to be 0, 1, or 2. Default: 1.\n   *\n   * 0 - No printed message during fit() call.\n   * 1 - In Node.js (tfjs-node), prints the progress bar, together with\n   *     real-time updates of loss and metric values and training speed.\n   *     In the browser: no action. This is the default.\n   * 2 - Not implemented yet.\n   */\n  verbose?: ModelLoggingVerbosity | 2;\n\n  /**\n   * List of callbacks to be called during training.\n   * Can have one or more of the following callbacks:\n   *   - `onTrainBegin(logs)`: called when training starts.\n   *   - `onTrainEnd(logs)`: called when training ends.\n   *   - `onEpochBegin(epoch, logs)`: called at the start of every epoch.\n   *   - `onEpochEnd(epoch, logs)`: called at the end of every epoch.\n   *   - `onBatchBegin(batch, logs)`: called at the start of every batch.\n   *   - `onBatchEnd(batch, logs)`: called at the end of every batch.\n   *   - `onYield(epoch, batch, logs)`: called every `yieldEvery` milliseconds\n   *      with the current epoch, batch and logs. The logs are the same\n   *      as in `onBatchEnd()`. Note that `onYield` can skip batches or\n   *      epochs. See also docs for `yieldEvery` below.\n   */\n  callbacks?: BaseCallback[]|CustomCallbackArgs|CustomCallbackArgs[];\n\n  /**\n   * Float between 0 and 1: fraction of the training data\n   * to be used as validation data. The model will set apart this fraction of\n   * the training data, will not train on it, and will evaluate the loss and\n   * any model metrics on this data at the end of each epoch.\n   * The validation data is selected from the last samples in the `x` and `y`\n   * data provided, before shuffling.\n   */\n  validationSplit?: number;\n\n  /**\n   * Data on which to evaluate the loss and any model\n   * metrics at the end of each epoch. The model will not be trained on this\n   * data. This could be a tuple [xVal, yVal] or a tuple [xVal, yVal,\n   * valSampleWeights]. The model will not be trained on this data.\n   * `validationData` will override `validationSplit`.\n   */\n  validationData?: [\n    Tensor|Tensor[], Tensor|Tensor[]\n  ]|[Tensor | Tensor[], Tensor|Tensor[], Tensor|Tensor[]];\n\n  /**\n   * Whether to shuffle the training data before each epoch. Has\n   * no effect when `stepsPerEpoch` is not `null`.\n   */\n  shuffle?: boolean;\n\n  /**\n   * Optional object mapping class indices (integers) to\n   * a weight (float) to apply to the model's loss for the samples from this\n   * class during training. This can be useful to tell the model to \"pay more\n   * attention\" to samples from an under-represented class.\n   *\n   * If the model has multiple outputs, a class weight can be specified for\n   * each of the outputs by setting this field an array of weight object\n   * or an object that maps model output names (e.g., `model.outputNames[0]`)\n   * to weight objects.\n   */\n  classWeight?: ClassWeight|ClassWeight[]|ClassWeightMap;\n\n  /**\n   * Optional array of the same length as x, containing\n   * weights to apply to the model's loss for each sample. In the case of\n   * temporal data, you can pass a 2D array with shape (samples,\n   * sequenceLength), to apply a different weight to every timestep of every\n   * sample. In this case you should make sure to specify\n   * sampleWeightMode=\"temporal\" in compile().\n   */\n  sampleWeight?: Tensor;\n\n  /**\n   * Epoch at which to start training (useful for resuming a previous training\n   * run). When this is used, `epochs` is the index of the \"final epoch\".\n   * The model is not trained for a number of iterations given by `epochs`,\n   * but merely until the epoch of index `epochs` is reached.\n   */\n  initialEpoch?: number;\n\n  /**\n   * Total number of steps (batches of samples) before\n   * declaring one epoch finished and starting the next epoch. When training\n   * with Input Tensors such as TensorFlow data tensors, the default `null` is\n   * equal to the number of unique samples in your dataset divided by the\n   * batch size, or 1 if that cannot be determined.\n   */\n  stepsPerEpoch?: number;\n\n  /**\n   * Only relevant if `stepsPerEpoch` is specified. Total number of steps\n   * (batches of samples) to validate before stopping.\n   */\n  validationSteps?: number;\n\n  /**\n   * Configures the frequency of yielding the main thread to other tasks.\n   *\n   * In the browser environment, yielding the main thread can improve the\n   * responsiveness of the page during training. In the Node.js environment,\n   * it can ensure tasks queued in the event loop can be handled in a timely\n   * manner.\n   *\n   * The value can be one of the following:\n   *   - `'auto'`: The yielding happens at a certain frame rate (currently set\n   *               at 125ms). This is the default.\n   *   - `'batch'`: yield every batch.\n   *   - `'epoch'`: yield every epoch.\n   *   - any `number`: yield every `number` milliseconds.\n   *   - `'never'`: never yield. (yielding can still happen through `await\n   *      nextFrame()` calls in custom callbacks.)\n   */\n  yieldEvery?: YieldEveryOptions;\n}\n\nexport function checkBatchSize(batchSize: number) {\n  tfc.util.assert(\n      batchSize > 0 && Number.isInteger(batchSize),\n      () => `batchSize is required to be a positive integer, but got ${\n          batchSize}`);\n}\n\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(\n    arrays: Tensor|Tensor[], start: number, stop: number): Tensor|Tensor[] {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {  // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(\n    arrays: Tensor|Tensor[], indices: Tensor1D): Tensor|Tensor[] {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(\n          array => (sliceArraysByIndices(array, indices) as Tensor));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(\n          arrays,\n          indices.dtype === 'int32' ? indices : tfc.cast(indices, 'int32'));\n    }\n  });\n}\n\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(\n    size: number, batchSize: number): Array<[number, number]> {\n  const output: Array<[number, number]> = [];\n  let batchStart = 0;\n  let batchEnd: number = null;\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n  return output;\n}\n\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors: Tensor|Tensor[]): Tensor[] {\n  const outs: Tensor[] = [];\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  }\n\n  // Make Tensors at least 2D.\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error(\n          'Expected tensor to be at least 1D, but received a 0D tensor ' +\n          '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n  return outs;\n}\n\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(\n    tensors: Tensor|Tensor[]|{[inputName: string]: Tensor},\n    refTensors: Tensor|Tensor[]|{[inputName: string]: Tensor}): void {\n  if (tensors == null) {\n    return;\n  }\n  const oldTensorIds: number[] = [];\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  const tensorsToDispose: Tensor[] = [];\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}\n"],"mappings":"AAAA;;;;;;;;;AAUA;;;AAIA,OAAO,KAAKA,GAAG,MAAM,uBAAuB;AAC5C,SAAQC,MAAM,QAAiB,uBAAuB;AACtD,SAAQC,UAAU,EAAEC,MAAM,EAAEC,mBAAmB,QAAO,yBAAyB;AA6I/E,OAAM,SAAUC,cAAcA,CAACC,SAAiB;EAC9CN,GAAG,CAACO,IAAI,CAACC,MAAM,CACXF,SAAS,GAAG,CAAC,IAAIG,MAAM,CAACC,SAAS,CAACJ,SAAS,CAAC,EAC5C,MAAM,2DACFA,SAAS,EAAE,CAAC;AACtB;AAEA;;;;;;;;;;;;;AAaA,OAAM,SAAUK,WAAWA,CACvBC,MAAuB,EAAEC,KAAa,EAAEC,IAAY;EACtD,IAAIF,MAAM,IAAI,IAAI,EAAE;IAClB,OAAO,CAAC,IAAI,CAAC;GACd,MAAM,IAAIG,KAAK,CAACC,OAAO,CAACJ,MAAM,CAAC,EAAE;IAChC,OAAOA,MAAM,CAACK,GAAG,CAACC,KAAK,IAAId,mBAAmB,CAACc,KAAK,EAAEL,KAAK,EAAEC,IAAI,GAAGD,KAAK,CAAC,CAAC;GAC5E,MAAM;IAAG;IACR,OAAOT,mBAAmB,CAACQ,MAAM,EAAEC,KAAK,EAAEC,IAAI,GAAGD,KAAK,CAAC;;AAE3D;AAEA;;;;;;;;;;;;;AAaA,OAAM,SAAUM,oBAAoBA,CAChCP,MAAuB,EAAEQ,OAAiB;EAC5C,OAAOpB,GAAG,CAACqB,IAAI,CAAC,MAAK;IACnB,IAAIT,MAAM,IAAI,IAAI,EAAE;MAClB,OAAO,IAAI;KACZ,MAAM,IAAIG,KAAK,CAACC,OAAO,CAACJ,MAAM,CAAC,EAAE;MAChC,OAAOA,MAAM,CAACK,GAAG,CACbC,KAAK,IAAKC,oBAAoB,CAACD,KAAK,EAAEE,OAAO,CAAY,CAAC;KAC/D,MAAM;MACL;MACA;MACA,OAAOjB,MAAM,CACTS,MAAM,EACNQ,OAAO,CAACE,KAAK,KAAK,OAAO,GAAGF,OAAO,GAAGpB,GAAG,CAACuB,IAAI,CAACH,OAAO,EAAE,OAAO,CAAC,CAAC;;EAEzE,CAAC,CAAC;AACJ;AAEA;;;;;;;;AAQA,OAAM,SAAUI,WAAWA,CACvBC,IAAY,EAAEnB,SAAiB;EACjC,MAAMoB,MAAM,GAA4B,EAAE;EAC1C,IAAIC,UAAU,GAAG,CAAC;EAClB,IAAIC,QAAQ,GAAW,IAAI;EAC3B,OAAOD,UAAU,GAAGF,IAAI,EAAE;IACxBG,QAAQ,GAAGD,UAAU,GAAGrB,SAAS;IACjC,IAAIsB,QAAQ,IAAIH,IAAI,EAAE;MACpBG,QAAQ,GAAGH,IAAI;;IAEjBC,MAAM,CAACG,IAAI,CAAC,CAACF,UAAU,EAAEC,QAAQ,CAAC,CAAC;IACnCD,UAAU,GAAGC,QAAQ;;EAEvB,OAAOF,MAAM;AACf;AAEA;;;;;;AAMA,OAAM,SAAUI,0BAA0BA,CAACC,OAAwB;EACjE,MAAMC,IAAI,GAAa,EAAE;EACzB,IAAID,OAAO,YAAY9B,MAAM,EAAE;IAC7B8B,OAAO,GAAG,CAACA,OAAO,CAAC;;EAGrB;EACA,KAAK,IAAIE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,OAAO,CAACG,MAAM,EAAE,EAAED,CAAC,EAAE;IACvC,MAAME,MAAM,GAAGJ,OAAO,CAACE,CAAC,CAAC;IACzB,IAAIE,MAAM,CAACC,IAAI,KAAK,CAAC,EAAE;MACrBJ,IAAI,CAACH,IAAI,CAAC3B,UAAU,CAACiC,MAAM,EAAE,CAAC,CAAC,CAAC;KACjC,MAAM,IAAIA,MAAM,CAACC,IAAI,KAAK,CAAC,EAAE;MAC5B,MAAM,IAAIC,KAAK,CACX,8DAA8D,GAC9D,WAAW,CAAC;KACjB,MAAM;MACLL,IAAI,CAACH,IAAI,CAACM,MAAM,CAAC;;;EAGrB,OAAOH,IAAI;AACb;AAEA;;;;;;;;;;;AAWA;AACA,OAAM,SAAUM,iBAAiBA,CAC7BP,OAAsD,EACtDQ,UAAyD;EAC3D,IAAIR,OAAO,IAAI,IAAI,EAAE;IACnB;;EAEF,MAAMS,YAAY,GAAa,EAAE;EACjC,IAAID,UAAU,YAAYtC,MAAM,EAAE;IAChCuC,YAAY,CAACX,IAAI,CAACU,UAAU,CAACE,EAAE,CAAC;GACjC,MAAM,IAAI1B,KAAK,CAACC,OAAO,CAACuB,UAAU,CAAC,EAAE;IACpCA,UAAU,CAACG,OAAO,CAACC,CAAC,IAAIH,YAAY,CAACX,IAAI,CAACc,CAAC,CAACF,EAAE,CAAC,CAAC;GACjD,MAAM,IAAIF,UAAU,IAAI,IAAI,EAAE;IAC7B;IACA,KAAK,MAAMK,IAAI,IAAIL,UAAU,EAAE;MAC7B,MAAMM,SAAS,GAAGN,UAAU,CAACK,IAAI,CAAC;MAClCJ,YAAY,CAACX,IAAI,CAACgB,SAAS,CAACJ,EAAE,CAAC;;;EAInC,MAAMK,gBAAgB,GAAa,EAAE;EACrC,IAAIf,OAAO,YAAY9B,MAAM,EAAE;IAC7B,IAAIuC,YAAY,CAACO,OAAO,CAAChB,OAAO,CAACU,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;MAC3CK,gBAAgB,CAACjB,IAAI,CAACE,OAAO,CAAC;;GAEjC,MAAM,IAAIhB,KAAK,CAACC,OAAO,CAACe,OAAO,CAAC,EAAE;IACjCA,OAAO,CAACW,OAAO,CAACC,CAAC,IAAG;MAClB,IAAIH,YAAY,CAACO,OAAO,CAACJ,CAAC,CAACF,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;QACrCK,gBAAgB,CAACjB,IAAI,CAACc,CAAC,CAAC;;IAE5B,CAAC,CAAC;GACH,MAAM,IAAIZ,OAAO,IAAI,IAAI,EAAE;IAC1B;IACA,KAAK,MAAMa,IAAI,IAAIb,OAAO,EAAE;MAC1B,MAAMI,MAAM,GAAGJ,OAAO,CAACa,IAAI,CAAC;MAC5B,IAAIJ,YAAY,CAACO,OAAO,CAACZ,MAAM,CAACM,EAAE,CAAC,KAAK,CAAC,CAAC,EAAE;QAC1CK,gBAAgB,CAACjB,IAAI,CAACM,MAAM,CAAC;;;;EAKnCW,gBAAgB,CAACJ,OAAO,CAACC,CAAC,IAAG;IAC3B,IAAI,CAACA,CAAC,CAACK,UAAU,EAAE;MACjBL,CAAC,CAACM,OAAO,EAAE;;EAEf,CAAC,CAAC;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}